---
title : "[Big Data]Spark"
data : 2021-02-01 00:15:28 -0400
categories : 프로그래머스인공지능스쿨
use_math: true
---
# Big Data: Spark 소개
- Contents
    1. 빅데이터 정의와 예
    2. 하둡의 등장과 소개
    3. Spark 소개
    4. 판다스와 비교
    5. Spark 데이터프레임, 데이터셋, RDD
    6. Spark 개발 환경
    7. Spark 맛보기
<br>
<br>

# 빅데이터의 정의와 예: 빅데이터란 무엇이며 어떤 예들이 있는가?
## 빅데이터의 정의1
- "서버 한대로 처리할 수 없는 규모의 데이터"
- 2012년 4월 아마존 클라우드 컨퍼런스에서 아마존의 data scientist인 존 라우저가 내린 정의. 분산 환경이 필요하느냐에 포커스!
- 판다스로 처리해야할 데이터가 너무 커서 처리가 불가능하다면 어떻게 할 것인가?
<br>

## 빅데이터의 정의2
- "기존의 소프트웨어로는 처리할 수 없는 규모의 데이터"
- 대표적인 기존 소프트웨어 오라클이나 MySQL과 같은 관계형 데이터베이스
    - 분산환경을 염두에 두지 않음
    - Scale-up 접근방식(vs. Scale-out)
        - 메모리 추가, CPU 추가, 디스크 추가
        - 여전히 서버 한대에서 돌아가는 데이터만 처리할 수 있음.
<br>

## 빅데이터의 정의3
- 4V(Volume, Velocity, Variety, Varecity)
    - Volume: 데이터의 크기가 대용량?
    - Velocity: 데이터의 처리 속도가 중요? = 데이터가 빠르게 많이 생성되는가
    - Variety: 구조화/비구조화 데이터 둘다? = 데이터의 특성이 구조화인지, 비구조화인지, 둘 다인지. 빅데이터의 경우 비구조화된 데이터가 더 많다. 
    - Veraciy: 데이터의 품질이 좋은지?
이 4가지 관점에서 빅데이터를 정의할 수 있다. Volume, Velocity가 제일 중요하다.  
<br>

## 빅데이터의 예제 - 디바이스 데이터
- 모바일 디바이스: 위치정보
- 스마트 TV
- 각종 센서 데이터(IoT 센서)
- 네트워킹 디바이스
<br>

## 빅데이터의 예 - 웹페이지
- 수십조개 이상의 웹 페이지 존재
- 이를 크롤하여 중요한 페이지를 찾아내고 (페이지 랭크) 인덱싱하는 것은 엄청난 크기의 데이터 수집과 계산을 필요로 함
- 사용자 검색어와 클릭 정보 자체도 대용량
    - 이를 마이닝하여 개인화 혹은 별도 서비스 개발이 가능
        - 검색어 자동 완성, 동의어 찾기, 통계 기반 번역, ...
- 이런 문제를 해결하면서 구글이 빅데이터 기술의 발전에 지대한 공헌을 하게 됨
<br>
<br>

# 하둡의 등장과 소개: 기존 기술과는 전혀 다른 방식을 택함으로써 대용량 데이터 처리를 가능하게 해준 하둡에 대해 알아보자
## 대용량 처리 기술이란?
- 분산 환경 기반(1대 혹은 그 이상의 서버로 구성)
    - 분산 컴퓨팅과 분산 파일 시스템이 필요
- Fault Tolerance
    - 소수의 서버가 고장나도 동작해야함
- 확장이 용이해야함
    - Scale Out 이라고 부름: 시스템의 용량을 높이기 위해서 메모리, 디스크를 더 붙이는 것이 아니라 서버를 더 붙이는 접근방식
<br>

## 하둡(Hadoop)의 등장
- 빅데이터 시대의 도래를 이끌어낸 최초의 대용량 분산처리 기술
- 구글에서 만든 두개의 논문에서 시작된 오픈소스
- Doug Cutting이 구글랩 발표 논문들에 기반해 만든 오픈소스 프로젝트
    - 2003년 The Google File System
    - 2004년 MapReduce: Simplified Data Processing on Large Cluster
- 처음 시작은 Nutch라는 오픈소스 검색엔진의 하부 프로젝트
    - 하둡은 Doung Cuting의 아들의 코끼리 인형의 이름
    - 2006년에 아파치 제단의 톱레벨 별개 프로젝트로 떨어져나옴
- 크게 두 개의 서브 시스템으로 구현됨
    - 분산 파일 시스템인 HDFS
    - 분산 컴퓨팅 시스템인 MapReduce
        - 새로운 프로그래밍 방식으로 대용량 데이터 처리의 효율을 극대화하는데 맞춤
<br>

## MapReduce 프로그래밍의 문제점
- 작업에 따라서는 MapReduce 프로그래밍이 너무 복잡해짐 -> 생산성이 떨어짐.
- 결국 Hive(하둡 위에서 돌아가는 SQL언어)처럼 MapReduce로 구현된 SQL 언어들이 다시 각광을 받게 됨
    - SQL on Hadoop
    - 빅데이터가 뜨면서 SQL이 한물 갔다고 평가되었지만 컴백!
- 또한 MapReduce는 기본적으로 배치 작업에 최적화(not realtime). 큰 데이터를 주기적으로 처리하는 프로그래밍 모델이다. 리얼타임으로 데이터를 처리하기에 적합하지 않다.
<br>

## 하둡(Hadoop)의 발전
- 하둡 1.0은 HDFS(분산파일시스템) 위에 MapReduce라는 분산컴퓨팅 시스템이 도는 구조
    - 다른 분산컴퓨팅 시스템은 지원하지 못함
- 하둡 2.0에서 아키텍처가 크게 변경됨
    - 하둡은 기반 분산처리 시스템이 되고 그 위에 애플리케이션 레이어가 올라가는 구조
    - Spark는 하둡 2.0위에서 애플리케이션 레이어로 실행됨
        - 손쉬운 개발을 위한 로컬 모드도 지원: 이번 강좌에서는 로컬 모드 사용
    ![png](/assets/images/2021-02-02/1.png)  