---
title : "[NLP]언어모델"
data : 2021-02-16 00:15:28 -0400
categories : 프로그래머스인공지능스쿨
use_math: true
---
# 자연어 처리: 언어모델
## 언어모델
- 목표: 문장이 일어날 확률을 구하는 것
    - 다음 문장 다음에 이어질 단어는?
    - 다음 두 문장 중 나타날 확률이 더 높은 것은?
- 왜 필요한가?
    - 기계번역
    - 맞춤법검사
    - 음성인식
- 언어모델: 연속적인 단어들에 확률을 부여하는 모델
    - $P(W) = P(w_1, w_1, ..., w_n)$
- 관련된 일: 연속적인 단어들이 주어졌을 때 그 다음 단어의 확률을 구하는 것
    - $P(w_n|w_1, w_1, ..., w_n)$
<br>

## P(W) 구하기
- 결합확률(joint probability) 구하기
    - $P(its, water, is, so, transparent, that)$
    - its, water, is, so, transparent, that의 단어 시퀀스가 나타날 확률
- Chain rule을 사용해보자
<br>

## Chain Rule
- 조건부확률
    - $P(B|A) = P(A, B)/P(A)$
    - $P(A, B) = P(A)P(B|A)
- 두 개 이상의 확률변수들의 경우
    - $P(A, B, C, D) = P(A)P(B|A)P(C|A, B)P(D|A, B, C)$
- 일반적인 경우
    - $P(x_1, x_2, ..., x_n) = P(x_1)P(x_2|x_1)...P(x_n|x_1, ..., x_{n-1})$
- P("its water is so transparent") = P(its) * P(water|its) * P(is | its water) * P(so | its water is) * P(transparent | its water is so)
<br>

## 조건부 확률 P(w|h)
P(the | its water is so transparent that) = Count(its water is so transparent that the) / Count(its water is so transpatent that)  
- 문제
    - 가능한 문장의 개수가 너무 많음
    - 이것을 계산할 수 있는 충분한 양의 데이터를 가지지 못할 것임
        - 보유한 말뭉치 중에서 its water is so transparent that 혹은 its water is so transparent that the를 정확하게 갖고 있는 문장이 거의 없을 수 있다. 
<br>

## Markov Assumption
- 한 단어의 확률은 그 단어 앞에 나타나는 몇 개의 단어들에만 의존한다 라는 가정
    - P(the | its water is so transparent that) $\approx$ P(the | that)
    - P(the | its water is so transparent that) $\approx$ P(the | transparent that)
    - 위와 같이 근사화할 수 있다.
    - $P(w_1, w_2, ..., w_n) \approx \prod_i P(w_i | w_{i-k} ... w_{i-1})$
<br>

## Unigram 모델 
- Markov Assumption을 극단적으로 사용
- 어떤 단어가 나타날 확률은 이전의 단어에 의존하지 않는다
- $P(w_1 w_2 ... w_n) \approx \prod_i P(w_i)$
<br>

## Bigram 모델
- $P(w_i | w_1 w_2 ... w_{i-1}) \approx P(w_i | w_{i-1})$
- 한 단어가 주어졌을 때 바로 직전의 단어에만 의존하는 조건부 확률을 다 곱하는 것.
- Unigram에 비해 자연스럽다.
<br>

## N-gram 모델
- 이것을 trigrams, 4-grams, 5-grams로 확장할 수 있다.
- 멀리 떨어진 단어들간의 관계를 완벽하게 모델링하진 못한다.
- 하지만 많은 경우 n-gram만으로도 좋은 결과를 얻을 수 있다.
<br>

## Bigram 확률 계산
- Maximum likelihood estimation
    - $P(w_i | w_{i-1}) = {count(w_{i-1}, w_i) \above 1pt count(w_{i-1})}$
    - $P(w_i | w_{i-1}) = {c(w_{i-1}, w_i) \above 1pt c(w_{i-1})}$
    - 두 단어가 연속적으로 나타나는 빈도수/한 단어가 나타나는 빈도수
<br>

## Bigram 확률 계산 - MLE 유도
사진
<br>

## Bigram 확률 계산 - 예제
- `</s>`는 문장이 끝나는 부호. vocabulary에 나타나지 않는 특수 기호로 지정한다.

```
<s> I am Sam </s>
<s> Sam I am </s>
<s> I do not like green eggs and ham </s>
```

- $P(I | <s>) = {2 \above 1pt 3} = .67$
    - `<s>`이 있는 문장 중에서 `<s>` 다음에 I가 오는 경우
- $P(Sam | <s>) = {1 \above 1pt 3} = .33$
- $P(am | I) = {2 \above 1pt 3} = .67$
- $P(</s> | Sam) = {1 \above 1pt 2} = .5$
    - Sam이 있는 문장 중에서 Sam 다음에 `</s>`가 오는 경우
- $P(Sam | am) = {1 \above 1pt 2} = .5$
- $P(do | I) = {1 \above 1pt 3} = .33$
<br>

## 모델평가
- 외재적 평가
    - 언어모델은 일반적으로 그 자체가 목표이기보다 특정 과제(맞춤법 검사 등)를 위한 부분으로서 쓰여진다
    - 따라서 언어모델이 좋은지 판단하기 위해선 그 과제의 평가지표를 사용하는 경우가 많다. 
- 내재적 평가
    - 외재적 평가는 시간이 많이 걸리는 단점
    - 언어모델이 학습하는 확률자체를 평가할 수 있다: Perplexity(언어모델이 얼마나 학습을 잘 하고 있는지 그 자체를 평가)
    - 이 기준으로 최적의 언어모델이 최종 과제를 위해서는 최적이 아닐 수도 있다.
    - 하지만 언어모델의 학습과정에 버그가 있었는지 빨리 확인하는 용도로 사용할 수 있다.
<br>

## Perplexity
- 언어모델이 얼마나 테스트 데이터를 높은 확률로 예측하는지를 평가하기 위한 지표
- 좋은 언어모델이란?
    - 테스트 데이터를 높은 확률로 예측하는 모델
    - Perplexity: 확률의 역수를 단어의 개수로 정규화한 값
    - Perplexity를 최소화하는 것이 확률을 최대화하는 것