---
title : "[인공지능 수학 - 통계학]18강 : 교차엔트로피"
data : 2020-12-10 00:15:28 -0400
categories : 프로그래머스인공지능스쿨
use_math: true
---
# 엔트로피
## 자기정보(Self-information): i(A)
- A : 사건
- $i(A) = log_b({1 \above 1pt P(A)}) = -log_bP(A)$
- 확률이 높은 사건:
    - 정보가 많지 않음(확률이 낮은 사건일수록 정보가 많음)
    - 예) 도둑이 들었는데 개가 짖는 경우보다 도둑이 들었는데 개가 안 짖는 경우가 더 많은 정보를 포함함
- 정보의 단위
    - $b = 2$ : bits
    - $b = e$ : nats
    - $b = 10$ : hartleys


## 엔트로피



# 교차엔트로피