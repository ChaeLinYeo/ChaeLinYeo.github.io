---
title : "[TIL]인공지능과 기계학습 소개"
data : 2021-01-18 00:15:28 -0400
categories : 프로그래머스인공지능스쿨
use_math: true
---
# 인공지능과 기계학습 소개
엔비디아 : 첨단 엣지 기술을 많이 전파하고 있다. 엔비디아의 CEO가 말하길 "소프트웨어가 결국 세상을 먹여살릴 것이고, AI가 소프트웨어를 먹여살릴 것이다."  
<br>

인공지능 : 인간의 학습능력과 추론능력, 지각능력, 자연언어의 이해능력 등을 컴퓨터 프로그램으로 실현한 기술  
- 무엇을 하고 싶은가? : **인간처럼** 생각하고 행동하는 기기의 탄생!
인공지능의 핵심은 "학습"이다!  
인공지능의 요소기술 중에 "머신러닝"이 있고, 머신러닝 안에서도 "딥러닝"에 대해 살펴볼 것이다.  
<br>

- 일상 속 인공지능
    - 음성인식
    - 추천시스템
    - 자율주행
    - 실시간 객체 인식
    - 로봇 
    - 번역
<br>

- 인공지능을 하려면, **Python**과 **Open Source**로 많이 **소통**해라!
- 인공지능 == 도구
    - 도구를 만드는 방법을 배우는 것도 중요하지만, 도구 사용 방법도 배워야 함!
    - 목적에 적당한 도구 고르기
    - 같은 도구도 어떻게 사용하느냐? 악용되지 않게 주의해야 함!
<br>
<br>
<br>




# 기계학습
## 요약
- 사람/동물의 학습
    - 예 : 수학, 과학, 역사 등 사고 영역 + 수영, 자전거 타기 등 행위 영역 포함
    - 예 : 파블로프의 개 실험
- 기계 학습
    - 기계도 학습이 가능한가? : 가능하다! 사람의 학습방법을 모방할 수 있다. 
    - **경험**을 통해 점진적으로 **성능**이 향상되는 기계를 만들 수 있을까? : 가능하다!
<br>
<br>

## 기계학습의 정의
- 인공지능이란? : 인간의 학습능력과 추론능력, 지각능력, 자연언어의 이해능력 등을 컴퓨터 프로그램으로 실현한 기술  
- 학습이란? : 경험의 결과로 나타나는, 비교적 지속적인 행동의 변화나 그 잠재력의 변화, 또는 지식을 습득하는 과정
- 기계학습이란?
    - 인공지능 초창기 정의
        - 컴퓨터가 경험을 통해 학습할 수 있도록 프로그래밍할 수 있다면, 세세하게 프로그래밍해야 하는 번거로움에서 벗어날 수 있다.
    - 현대적 정의
        - **최적의 프로그램(알고리즘)**을 찾는 행위
            - **경험** E를 통해
            - 주어진 **작업** T에 대한
            - **성능** P의 향상
            - E*T = P
<br>

- 기계학습과 전통적인 프로그래밍의 비교
    - 전통적인 프로그래밍 : 입력을 주고 사람이 알고있는 규칙에 대해서 결과를 찾아가는 것을 시퀀스하게 연속적으로 나열하고 서술하는 것
    - 기계학습 : 입력과 원하는 결과를 주고 그 안에서 규칙을 찾는다. 해당 문제를 잘 풀 수 있는 규칙을 찾아가는 것!
<br>
<br>

## 지식기반 방식에서 기계 학습으로의 대전환
- 인공지능의 주도권 전환
    - **지식 기반 -> 기계 학습 -> 심층 학습(deep learning), 표현 학습(representation learning)**
    - **데이터 중심** 접근방식으로 전환
<br>
<br>

## 기계 학습 개념
- 문제(task)
- 예측(prediction)
    - **회귀(regression)** : 목표치가 실수(연속적인 값)
    - **분류(classification)** : 목표치가 종류 혹은 분류의 값인 것(카테고리, 클래스 값)
- 훈련집합(training set)
    - 입력과 각각 대응되는 label로 이루어진다.
- 테스트 데이터, 추론데이터
<br>

- 관찰된 데이터들을 어떻게 설명할 것인가?
    - 가설 : 눈대중으로 데이터 양상이 직선 형태를 보임 -> 모델을 직선으로 선택 가정. 어떤 형태의 직선인지는 모름. 
    - 가설인 직선 모델의 수식(매개변수가 포함된)을 세움
<br>

- 기계 학습의 훈련
    - 주어진 문제인 예측을 가장 정확하게 할 수 있는 **최적의 매개변수를 찾는 작업**
    - **처음은 임의의 매개변수 값에서 시작하지만, 개선하여 정량적인 최적 성능에 도달**
    - 좋은 예측의 정량적 판단은?
        - 세운 가설과 실제 훈련집합의 차이를 오차(에러, loss)라고 해서 이를 판단의 기준으로 삼는다.
- 훈련을 마치면, 추론을 수행
    - 새로운 특징에 대응되는 목표치의 예측에 사용
<br>

- 기계 학습의 궁극적인 목표
    - 훈련집합에 없는 새로운 데이터에 대한 오류를 최소화(새로운 데이터 = 테스트 집합)
    - 테스트 집합에 대한 높은 성능을 일반화(generalization) 능력이라 부름
<br>

- 기계학습의 필수요소
    - 학습할 수 있는 데이터가 있어야 함
    - 데이터 안에 규칙이 존재해야 함
    - 수학적으로 설명 불가능
<br>
<br>

## 특징 공간에 대한 이해
### 1차원과 2차원 특징 공간
- 모든 데이터는 정량적으로 표현되며, 특징 공간 상에 존재
- 1차원 특징 공간 : x, y축으로 이루어짐. 입력과 결과가 일대일로 이루어짐.
- 2차원 특징 공간
    - 특징 벡터 표기 : $x = (x_1, x_2)^T$
        - 입력에 대해 각각 서술하고 있는 특징들.
        - 예 : x=(체온, 두통)^T, y=감기여부 -> 체온과 두통이 어떻게 주어지면 감기여부를 판단하는가?
<br>

### 다차원 특징 공간
- 다차원 특징 공간
    - Iris 데이터셋(4차원 공간 데이터셋)
    - 3차원 이상의 특징 공간
    - 이미지, 동영상
- d-차원 데이터
    - 특징 벡터 표기 : $x=(x_1, x_2, ..., x_d)^T$
    - d-차원 데이터를 위한 학습 모델의 예
        - 직선 모델을 사용하는 경우 매개변수 수 = $d+1$
            - y=ax+b이라면 매개변수가 a, b로 2개임
        - 2차 곡선 모델을 사용하면 매개변수 수가 지수적으로 증가, 매개변수 수 = $d^2+d+1$
    - 거리 : 차원에 무관하게 수식 적용 가능함(유클리드 거리)
<br>

### 특징 공간 변환과 표현 학습
- 차원의 저주
    - 차원이 높아짐에 따라 발생하는 현실적인 문제들
    - 1차원을 5개의 데이터로 채워서 규칙을 찾기 : 쉬움
    - 3차원을 5개의 데이터로 채워서 규칙을 찾기 : 어려움
    - 차원이 높아질수록 유의미한 표현을 찾기 위해 지수적으로 많은 데이터가 필요함. 문제의 규칙을 찾기도 더 어려워짐.
<br>

### 특징 공간 변환과 표현 문제
우리 모든 데이터들은 실제로 특징 공간 안에 존재한다.  
- 선형 분리 불가능한 원래 특징 공간
    - 직선 모델을 적용하면 75% 정확도 한계
        - 2차원 공간 안의 데이터들의 규칙을 찾아내는 것. 직선으로 나눠서 찾는 것은 불가능, 파라미터를 아무리 잘 조정해도 75%가 한계.
- **공간 변환**을 통해 직선 모델로 100% 정확도
    - 원래 특징 벡터 $x = (x_1, x_2)^T$ -> 변환된 특징 벡터$x' = (x_1',x_2')^T$
    - 새롭게 변환된 공간안에서 직선으로 나눌 수 있다. 
공간이 변형되고, 그 안에서부터 공간이 변형될 수 있는 규칙을 새롭게 정의하면 우리가 원공간에서 제대로 해결해지 못했던 문제들을 제대로 표현할 수 있다. 이를 "표현문제"라고 한다.  
<br>

- 표현문제의 예
    - Carteesian coordiantes -> Polar coordinates
    - 데이터는 그대로, 좌표계를 바꿔서 직선으로 경계를 나눌 수 있다.

데이터가 특징공간 안에 있는 구조적인 표현 자체를 "representation"이라고 한다. representation을 배우고 활용해서 공간변환으로 문제를 해결하는 것을 "표현문제"라고 한다.  
주어져있는 데이터가 존재하는 구조적 표현을 배워서 다른 좌표계로 변환하는 것.  
- 표현학습
    - **좋은 특징 공간을 자동으로 찾는 작업**
    - input -> representation -> output
<br>

- 심층 학습
    - 표현학습의 하나로 다수의 은닉층을 가진 **신경망**을 이용하여 **최적의 계층적인 특징을 학습**
    - 간단한 표현부터 추상화된 표현까지 세분화해서 계층적으로 학습을 하는 것이 일반적인 표현학습과의 차이이다.
    - 아래쪽 은닉층은 저급 특징(선, 구석점 등), 위쪽은 추상화된 특징(얼굴, 바퀴 등) 추출
    - image, text, speech 모든 분야에 쓰일 수 있음
    - 문제를 푸는데 더 효과적임
<br>
<br>

## 인공지능과 기계 학습의 간략한 역사
- 인공신경망의 역사
    - 1940-1960 : 인공두뇌학
    - 1980-1990 : 결합설
    - 2006-현재 : 심층학습
<br>
<br>

## 기술 추세
**인공지능 범주**
- AI (ex : Knowledge bases)
    - Machine Learning (ex : Logistic regression)
        - Representation learning (ex : Shallow autoencoders)
            - Deep learning (ex : MLPs)
딥러닝을 중심적으로 배울 것이다.  
- 기계학습 알고리즘과 응용의 **다양화**
- **표현학습**이 중요해짐
- **심층학습**이 기계 학습의 **주류**
- 심층학습은 현대 인공지능 실현에 핵심 기술
<br>
<br>

## 사회적 전망
- 인공지능의 단계
1. 약인공지능 : 인간이 지시한 명령의 틀 안에서만 일하기 때문에 예측과 관리가 용이. 지금의 인공지능의 수준.
2. 강인공지능 : 인간이 할 수 있는 어떠한 지적인 업무도 성공적으로 해낼 수 있는(가상적인) 기계의 지능
3. 초인공지능 : 인공지능의 발전이 가속화되어 모든 인류의 지성을 합친 것보다 더 뛰어난 인공지능. 인간을 넘어서는 특이점
<br>
<br>

## 데이터에 대한 이해
- 과학 기술의 정립 과정
    - 데이터 수집 -> 모델 정립(가설) -> 예측 -> 반복..
- 기계학습
    - 기계학습은 복잡한 문제를 다룸
    - 단순한 수학 공식으로 표현 불가능
    - **데이터를 설명할 수 있는 학습 모델을 찾아내는 과정**
        - Get Raw Data -> Clean Data -> Build Model -> Predict
        - 이 과정 중 Get Raw Data, Clean Data, Build Model이 제일 중요하다. 모델을 만드는것도 중요하지만, 데이터를 만드는 것이 더 중요할 때도 있다.
        - 데이터가 많을수록 규칙에 대한 이해도가 증가하고, 적을수록 규칙에 대한 이해도가 감소한다.
<br>
<br>

## 데이터 생성 과정
- 데이터 생성 과정을 완전히 아는 인위적 상황 (가상)
    - 확률통계 범위의 문제로, 기계학습에서는 실제로 존재하지 않음
    - 두개의 주사위를 던져 나온 눈의 합을 x라고 할 때, 특정 점수를 받는 게임
        - x를 알면 정확히 y를 예측할 수 있음
        - x의 발생 확률 P(x)를 정확히 알 수 있음
        - P(x)를 알고 있으므로, 새로운 데이터 생성 가능
- 실제 기계 학습 문제 (현실)
    - **데이터 생성 과정을 알 수 없음**
    - 단지 주어진 **훈련집합** X, Y로 **가설모델**을 통해 **근사 추정**만 가능 
기계학습은 위에서 인위적으로 모든 데이터 생성하는 것을 아는 문제를 해결하는 것이 아니라, 우리가 데이터의 생성 원리 자체를 모르는 문제를 접근하고 규칙을 찾아가는 것이다.  
우리가 다루는 기계학습은, 규칙을 모르지만 존재하고, 수학적으로 정의되지 않는 규칙을 갖고있다. 규칙을 설명하는 것은 규칙에 의해서 발현되는 훈련집합에 대해서 그 훈련집합을 잘 학습시키면 규칙을 설명할 수 있다.  
<br>
<br>

## 데이터의 중요성
- 데이터의 양과 질
    - 주어진 과업에서 적합한 다양한 데이터를 **충분한 양**만큼 수집 -> 과업 **성능 향상**
    - 주어진 과업에 관련된 데이터 확보는 아주 중요함
- 공개 데이터
    - 기계 학습의 대표적인 3가지 데이터: Iris, MNIST, ImageNet
    - UCI 저장소 repository (2017년 11월 기준으로 394개 데이터 제공)
- Irist 데이터베이스는 150개 샘플 각가에 대해 꽃받침 길이, 꽃받침 너비, 꽃잎 길이, 꽃잎 너비를 측정하여 기록한 것이다. 따라서 4차원 특징 공간이 형성되며 목푯값은 3종을 숫자로 표시함으로써 1, 2, 3 값 중의 하나이다. http://archive.ics.uci.edu/ml/datasets/Iris 에서 다운가능!
- MNIST 데이터베이스는 훈련집합 60,000자, 테스트집합 10,000자를 제공한다. http://yann.lecun.com/exdb/mnist에서 다운 가능. 2017년 8월 기준으로 Ciresan2012 논문이 0.23%의 오류율로 최고 자리를 차지하고 있다(무려 10,000 샘플에서 단지 23개만을 틀린 것!)
- ImageNet 데이터베이스는 정보검색 분야에서 만든 WordNet의 단어 계층 분류를 그대로 따랐고, 분류마다 수백에서 수천 개의 영상을 수집했다. 총 21,841개 부류에 대해 총 14,197,122개의 영상을 보유하고 있다. http://image-net.org에서 다운가능!
<br>
<br>

## 데이터베이스 크기와 기계 학습 성능
- 데이터의 적은 양 -> 차원의 저주와 관련
    - 예) MNIST : 28*28(=784) 픽셀로 단순히 흑백(=2)으로 구성된다면 각각의 픽셀은 차원(특징)이므로 서로 다른 총 샘플 수는 $2^784$가지이지만, MNIST는 고작 6만 개 샘플
    - 방대한 데이터 공간에 희소한 데이터 영역만 채워진다.
    - 차원의 저주 관점에서 보면 규칙을 제대로 찾을 수 없다. 하지만 MNIST는 규칙을 잘 찾는다. 왜일까?
<br>

- 적은 양의 데이터베이스로 어떻게 높은 성능을 달성하는가?
    - 방대한 공간에서 실제 데이터가 발생하는 곳은 매우 작은 부분 공간임 -> **데이터 희소(data sparsity)특성** 가정
    - **매니폴드(많이 + 끼다) 가정(manifold assumption or manifold hypothesis)** 즉 고차원의 데이터를 저차원에서 바라보는 관점.
        - 고차원의 데이터는 관련된 낮은 차원의 매니폴드에 가깝게 집중되어 있음
        - 일정한 규칙에 따라 매끄럽게 변화한다.
차원의 저주 관점에서 보면 MNIST는 제대로 학습이 이뤄질 수 없다. 하지만 학습이 잘 이뤄지는 이유는 내재되어있는 고차원의 데이터를 발현할 때 특정한 규칙에 의해 발현되기 때문이다.  
즉, 차원의 저주와 대비됨에도 불구하고, 고차원을 다 채울 수 없는 sparse한 데이터에 대해 성능이 잘 나오는 이유는 매니폴드 과정 즉 데이터가 생성될 때 내재된 규칙에 의해서 생성되기 때문에 희소한 영역에서 데이터들이 생기기 때문에, 희소한 영역에 있는 우리가 집중해야 할 부분의 데이터들만 가지고도 충분히 학습하고 규칙을 설명할 수 있다.  
<br>
<br>

## 데이터 가시화
- 4차원 이상의 초공간은 한꺼번에 가시화 불가능
- 여러 가지 가시화 기법
    - 2개씩 조합하여 여러 개의 그래프 그림
    ![png](/assets/images/2021-01-18/1.png)  
    - 고차원 공간을 저차원으로 변환하는 기법들 
        - 매니폴드를 잘 찾으면 고차원의 특징들을 저차원에서도 잘 보존할 수 있다.
<br>
<br>

## 간단한 기계 학습의 예
- **선형회귀(linear regression)**문제
    - 분류 : x에 따른 y값이 종류를 나누는 경우
    - 회귀 : x에 따른 y값이 연속적인 실수인 경우
$y = wx + b$  
위 식의 직선 모델(가설)을 사용하므로 두 개의 매개변수 $\Theta = (w,b)^T$를 갖는다.  
x, y가 잘 발현될 수 있도록 모델을 통해 최적의 파라미터를 학습해야 한다.  
<br>

- 성능을 측정하기 위한 **목적 함수(objective function)** 또는 **비용 함수(cost function)**
    - 선형 회귀를 위한 목적함수, **평균제곱오차, MSE(Mean Squared error)**
        - $J(\Theta) = {1 \above 1pt n}\sum_{i=1}^{n}(f_\Theta(x_i) - y_i)^2$
    - $f_\Theta(x_i)$는 예측함수의 **예측출력**, $y_i$는 예측함수가 맞춰야 하는 **실제 목표치**
    - $f_\Theta(x_i) - y_i$는 **오차(error)** 혹은 **손실(loss)**
    - 처음에는 최적 매개변수 값을 알 수 없으므로 임의의 난수로 $\Theta_1 = (w_1, b_1)^T$ 설정
        - $\Theta_2 = (w_2, b_2)^T$로 개선 -> $\Theta_3 = (w_3, b_3)^T$로 개선 -> $\Theta+3$는 최적해 $\widehat{\Theta}$, 모델을 확정하게 됨
        - 이때 $J(\Theta_1) > J(\Theta_2) > J(\Theta_3)$
            - 손실함수 $J(\Theta)$의 값을 점점 줄여서 모델을 향상시킨다.
<br>

- 선형 회귀 문제와 매개변수 최적화 관계의 예
    - 선형회귀는 회귀문제를 직선으로 가설을 세우고 푸는 것이다. 
    - 어느 기울기 파라미터에서 시작하든지 간에 MSE를 최소화하는 파라미터를 찾는 탐색과정을 진행할 것이고, 이 탐색과정은 최적화 이론에 의해서 진행한다. 최적화 이론은 크게 두가지로 나뉜다.
        - Convex : 최적해가 1개
        - Non Convex : 신경망, 즉 최적해가 존재하지 않을수도 있고 찾기 어려울 수 있다. greedy한 방법
<br>

- 기계학습이 할 일을 공식화하면, **$\widehat{\Theta} = argmin_\Theta J(\Theta)$**
    - 주어진 손실함수를 가장 작게 만드는 theta값(파라미터)을 찾는 것이다.
    - 기계 학습은 **작은 개선을 반복**하여 **최적의 해**를 찾아가는 수치적 방법으로 위의 식을 푸는 것이다.
- 알고리즘으로 표현하면 다음과 같다.  
```
입력 : 훈련집합 X와 Y  
출력 : 최적의 매개변수 $\widehat{\Theta$  
난수를 생성하여 초기 해 $\Theta_1$을 설정한다.  
t = 1  
while($J(\Theta_t)$가 0.0에 충분히 가깝지 않음) // 수렴 여부 검사  
    $J(\Theta)_t$가 작아지는 방향 $\Delta \Theta_t$를 구한다. // $\Delta \Theta_t$는 주로 미분을 사용하여 구함  
    $\Theta_{t+1} = \Theta_t + \Delta \Theta_t$  
    t = t + 1  
$\widehat{\Theta} = \Theta_t$  
```
<br>

- 좀더 현실적인 상황
    - 지금까지는 데이터가 선형을 이루는 아주 단순한 상황을 고려함
    - **실제** 세계는 선형이 아니며 **잡음**이 섞임 -> **비선형** 모델이 필요
<br>

- 기게학습 요소
    - 카드 승인 예제
        - 누구는 발급해주고, 누구는 발급해주지 않을 것인가?
        - 발급할지/안할지 2진으로 분류하는 binary classification
    - 요소
        - input
        - output
        - target distribution
        - data
        - hypothesis
        - data를 통해 target distribution을, 즉 생성의 원리를 유추할 수 있다. 즉 보이지 않는 규칙을 설명한다. 모델을 통해 가설을 설명하는 과정이 기계학습이다.
<br>

- 기계학습 설정
    - 교사학습의 경우
![png](/assets/images/2021-01-18/2.png)  
목적함수는 맞았는지/틀렸는지를 정량화할 수 있다.  
가설의 최적화는 목적함수를 최소화할 수 있도록 optimize한다.  
<br>
<br>

## 과소적합과 과잉적합
- **과소적합(underfitting)**
    - **모델의 '용량이 작아' 오차**가 클 수밖에 없는 현상
    - 대안 : 비선형 모델을 사용
        - 2차, 3차, 4차, 12차 다항식 곡선을 석택
        - 1차(선형)에 비해 오차가 크게 감소함
- **과잉적합(overfitting)**
    - 12차 다항식 곡선을 채택한다면 훈련집합에 대해 거의 완벽하게 근사화함
    - 하지만 **'새로운'데이터**를 예측한다면 큰 문제 발생
    - 이유는 **'모델의 용량(capacity)이 크기' 때문에** 학습과정에서 **잡음까지 수용** -> 과잉적합 현상
        - 훈련집합에 과몰입해서 단순 암기했기 때문임
    - 적절한 용량의 모델을 선택하는 모델 선택 작업이 필요함
<br>

- 1차~12차 다항식 모델의 비교 관찰
    - 1~2차는 훈련집합과 테스트집합 모두 낮은 성능: 과소적합
    - 12차는 훈련집합에 높은 성능을 보이나 테스트집합에서는 낮은 성능 -> 낮은 일반화 능력: 과잉적합
    - 3~4차는 훈련집합에 대해 12차보다 낮겠지만 테스트집합에는 높은 성능 -> 높은 일반화 능력: 적합 모델 선택
        - 데이터의 자유도 = 모델(가설)의 자유도인 경우!
- **모델의 일반화 능력과 용량 관계** 
    ![png](/assets/images/2021-01-18/3.png)  
    - 딥러닝의 경우 "규제"를 사용한다. 원래 모델이 갖추고 있던 용량을 줄이는 것이다.
<br>
<br>

## 편향(bias)와 분산(변동, variance)
- 편향 : 정답을 제대로 못 맞추고 치우쳐진 것. 언더피팅일수록 편향이 커지고 오버피팅일수록 편향이 작아짐.
- 분산 : 데이터가 변함에 따라서 모델이 바뀌는 정도. 언더피팅일수록 분산이 낮고 오버피팅일수록 분산이 커짐.
- **훈련집합**을 **여러 번 수집**하여 1차~12차에 반복 적용하는 실험
    - 2차는 매번 큰 오차 -> 편항이 큼. 하지만 비슷한 모델을 얻음 -> 낮은 변동(언더피팅)
    - 12차는 매번 작은 오차 -> 편향이 작음. 하지만 크게 다른 모델을 얻음 -> 높은 변동(오버피팅)
    - 일반적으로 용량이 작은 모델은 편향이 크고 분산이 작음
    - 일반적으로 용량이 큰 모델은 편향이 작고 분산이 큼
    - 편향과 분산은 상충(trade-off)관계
<br>

- 기계 학습의 목표
    - **낮은 편향과 낮은 분산을 가진 예측 모델을 만드는 것**이 목표
    - 하지만 모델의 **편향과 분산은 상충 관계**
    - 따라서 **편향을 최소로 유지하며 분산도 최대로 낮추는 전략 필요**
<br>

- 편향과 분산의 관계
    - **용량 증가 -> 편향 감소, 분산 증가 경향**
    - 일반화 오차 성능 (= 편향+분산)은 U형의 곡선을 가짐
    ![png](/assets/images/2021-01-18/4.png)  
<br>
<br>

## 검증집합과 교차검증을 이용한 모델 선택 알고리즘
### 검증집합을 이용한 모델 선택
    - 훈련집합, 테스트집합과 다른 별도의 **검증집합(validation set)**을 가진 상황(**데이터 양이 많은 경우에 검증집합을 사용한다**)
- 알고리즘
```
입력 : 모델집합, 훈련집합, 검증집합, 테스트집합
출력 : 최적 모델과 성능
for (모델집합에 있는 각각의 모델)
    모델을 훈련집합으로 학습시킨다.
    검증집합으로 학습된 모델의 성능을 측정한다. //검증 성능 측정
가장 높은 성능을 보인 모델을 선택한다.
테스트집합으로 선택된 모델의 성능을 측정한다.
```
<br>

### 교차검증(cross validation)
    - 비용 문제로 별도의 **검증집합이 없는 상황**에 유용한 모델 선택 기법(**데이터 양이 적은 경우에 검증집합을 사용한다**)
- 알고리즘
```
입력 : 모델집합, 훈련집합, 검증집합, 테스트집합, 그룹 개수 k
출력 : 최적 모델과 성능
훈련집합을 k개의 그룹으로 등분한다
for (모델집합에 있는 각각의 모델)
    for (i=1 to k)
        i번째 그룹을 제외한 k-1개 그룹으로 모델을 학습시킨다.
        학습된 모델의 성능을 j번째 그룹으로 측정한다.
    k개 성능을 평균하여 해당 모델의 성능으로 취한다.
가장 높은 성능을 보인 모델을 선택한다.
테스트집합으로 선택된 모델의 성능을 측정한다.
```
<br>

### 부트스트랩(bootstrap)
- 임의의 **복원추출 샘플링 반복**
    - 데이터 분포가 불균형일 때 적용. 보안 등 이상탐지 문제에서 많이 쓰임!
- 알고리즘
```
입력 : 모델집합, 훈련집합, 검증집합, 테스트집합, 샘플링 비율 p, 반복횟수 T
출력 : 최적 모델과 성능
for (모델집합에 있는 각각의 모델)
    for (i=1 to T)
        훈련집합 X에서 pn개 샘플을 뽑아 새로운 훈련집합 X'를 구성한다. 이때 대치를 허용한다.
        X'로 모델을 학습시킨다.
        X - X'를 이용하여 학습된 모델의 성능을 측정한다.
    T개 성능을 평균하여 해당 모델의 성능으로 취한다.
가장 높은 성능을 보인 모델을 선택한다.
테스트집합으로 선택된 모델의 성능을 측정한다.
```
<br>
<br>

## 모델 선택의 한계와 현실적인 해결책
- 위의 알고리즘을 통해 주어진 모델 집합에서 선택
    - 현실에서는 학습 모델들이 아주 다양함
        - 신경망(MLP, deep MLP, CNN, RNN 등 아주 많음)
        - support vector machine(SVM)
        - decision trees
- 현실에서는 경험으로 큰 틀(가설) 선택한 후
    - 모델 선택 알고리즘으로 세부 모델 선택함
    - 우리가 선택한 모델에 데이터 생성 과정을 끼워 넣는 것
- 현대 기계 학습의 전략
    - **용량이 충분히 큰 모델을 선택**한 후, 선택한 **모델이 정상을 벗어나지 않도록 여러 규제(regularization) 기법을 적용함**
    - 즉 경험적인 접근방법과 달리, 데이터 생성 과정에서부터 규제를 적용하고, 선택한 모델에 집어넣는 것.
<br>
<br>

## 규제 방법 : 데이터 확대
- **데이터를 더 많이 수집하면 일반화 능력이 향상됨**
- 데이터 수가 많을수록 오류가 적어진다.
- 데이터 수집은 **많은 비용**이 듦
    - 실측자료를 사람이 일일이 라벨링을 해야함
- 인위적으로 데이터 확대(data augmentation)
    - 데이터를 재활용해서 데이터를 확대하는 것.
    - 훈련집합에 있는 샘플을 **변형(transform)**함
        - 약간 회전 또는 왜곡시키기(고유 특성 변하지 않게 주의!)
<br>
<br>

## 규제 방법 : 가중치 감쇠
- 가중치를 작게 조절하는 기법
    - 가중치는 모델의 용량과 연관성이 크다. 가중치를 낮추는 것은 모델의 용량을 낮추는 것이다. 즉 오버피팅을 감소시킨다.
    - 예를 들어 12차 곡선은 가중치가 매우 큼.
    - 가중치 감쇠는 **개선된 목적함수**를 이용하여 **가중치를 작게 조절**하는 규제 기법
    - $J(\Theta) = {1 \above 1pt n}\sum_{i=1}^{n}(f_\Theta(x_i) - y_i)^2 + \lambda\left \| \Theta \right \|_{2}^{2}$
    - 원래 가지고 있는 모델의 용량이 다 발현되지 못하게 용량을 줄여서 variance를 줄여주는 것이다. 위 식의 "규제항" $\lambda\left \| \Theta \right \|_{2}^{2}$을 통해 한다.
- 가중치 감쇠를 가진 선형 회귀 예
    - $J(\Theta) = {1 \above 1pt n}\sum_{i=1}^{n}(f_\Theta(x_i) - y_i)^2 + \lambda\left \| \Theta \right \|_{2}^{2}$
        - ${1 \above 1pt n}\sum_{i=1}^{n}(f_\Theta(x_i) - y_i)^2$ : 훈련집합의 오차
        - $\lambda\left \| \Theta \right \|_{2}^{2}$ : 선호도. w가 다 발현되지 못하게 규제를 걸어주는  것이다.
    - $\lambda$는 주어진 **가중치의 감쇠 선호 정도를 제어**
        - $\lambda=0$ : 감쇠 없음
        - 큰 $\lambda$는 가중치가 더 작아지도록 함
<br>
<br>

## 지도 방식에 따른 유형
- **지도 학습(supervised learning)**
    - 특징 벡터 X와 목표치 Y(정답 있음)가 모두 주어진 상황
    - **회귀(regression)**와 **분류(classification)** 문제로 구분
- **비지도 학습(unsupervised learning)**
    - 특징 벡터 X는 주어지는데 목표치 Y가 주어지지 않는 상황(정답 없음)
    - **군집화(clustering)** 과업(고객 성향에 따른 맞춤 홍보 응용 등)
    - **밀도 추정(density estimation)**, **특징 공간 변환** 과업 (ex : PCA)
- **강화 학습(reinforcement learning)**
    - (상대적)목표치가 주어지는데, 지도 학습과 다른 형태임 (==보상, reward)
    - 예)바둑
        - 수를 두는 행위가 샘플인데, 게임이 끝나면 목표치 하나가 부여됨
            - 이기면 1, 패하면 -1을 부여
        - 게임을 구성한 샘플들 각각에 목표치를 나누어 주어야 함
    - 환경과 인터렉티브한 상호작용이 가능한 학습방법
- **준지도 학습(semi-supervised learning)**
    - **일부는 X와 Y를 모두 가지지만, 나머지는 X만 가진 상황**
    - 최근, 대부분의 데이터가 X의 수집은 쉽지만, Y는 수작업이 필요하여 **최근 중요성 부각**
<br>
<br>

## 다양한 기준에 따른 유형
- **오프라인 학습과 온라인 학습**
    - **보통**은 **오프라인 학습**을 다룸
    - **온라인 학습**은 IoT 등에서 추가로 발생하는 데이터 샘플을 가지고 **점증적 학습** 수행
- **결정론적 학습(deterministic learning)**과 **확률적 학습(stochastick learning)**
    - 결정론적에서는 **같은 데이터**를 가지고 **다시 학습**하면 **같은 예측 모델**이 만들어짐
    - 확률적 학습은 **학습과정에서 확률 분포를 사용**하므로 **같은 데이터**로 다시 학습하면 **다른 예측 모델**이 만들어짐. 불확실성을 이용함.
    - RBM, DBN
- **분별 모델(discriminative models)**과 **생성 모델(generative models)**
    - **분별 모델**은 분류 예측에만 관심. 즉 **P(y|x)의 추정**에 관심, 즉 x에서 y가 되는 상관관계에 관심이 있음. 분류 모델과는 다름.
    - **생성 모델**은 **P(x) 또는 P(x|y)를 추정**함, 즉 x자체에 관심이 있음.
        - 따라서 **새로운 샘플**을 **'생성'**할 수 있음
        - GAN. RBM