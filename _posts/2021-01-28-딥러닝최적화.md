---
title : "[Deep Learning: 신경망의 기초]Deep Learning 최적화"
data : 2021-01-28 00:15:28 -0400
categories : 프로그래머스인공지능스쿨
use_math: true
---
# 심층학습 최적화
## 활성함수
- 선형 연산 결과인 활성값 $z$에 비선형 활성함수 $\tau$를 적용하는 과정(은닉층에서 일어남)
- 활성함수 변천사
    - 선형 -> 계단 -> tanh -> ReLU
    - sigmoid 함수는 활성값이 커지면 포화 상태가 되고 경사도가 0에 가까운 값을 출력함 -> **매개변수 갱신(학습)이 매우 느린 요인**
<br>

- **ReLU(Rectified Linear Unit) 활성함수**
    - 경사도 포화(gradient saturation) 문제 해소
        - 0을 기점으로 해서 그 이전것은 0이고, 0 이후부터는 linear하게 자기자신을 내보냄.
        - $z = w^T\widetilde{x} + b$
        - $y = ReLU(z) = max(0, z)$
            - 0과 자기 값을 비교해서 자기 값이 0보다 작으면 0을 출력, 자기 값이 0보다 크면 그대로 출력
    - ReLU의 변형
        - Leaky ReLU(보통 $\alpha = 0.01$을 사용) : 자기자신 z가 0보다 크면 0 z 출력, 0보다 작은 경우 $\alpha z$ 출력
        - Parametric ReLU($\alpha$를 학습으로 알아냄)
<br>

- 다양한 활성함수들
    - Sigmoid
    - tanh
    - ReLU
    - Leaky ReLU
    - Maxout
    - ELU
- 최근의 활성 함수들은 다음의 문제들을 해결하고자 함
    - 포화된 영역이 경사도가 작아짐
    - 출력값이 영 중심 아님
    - 다소 높은 연산량
<br>
<br>

## 배치 정규화
- **공변량 변화(covariate shift)** 현상
    - 훈련집합과 테스트집합의 분포가 다름
    - 내부의 공변량 변화(internal covariate shift)
        - 학습이 진행되면서 첫번째 층의 매개변수가 바뀜에 따라 바뀜 -> 두번째 층 입장에서 보면 자신에게 입력되는 **데이터의 분포가 수시로 바뀌는 셈**
        - 층2, 층3, ... 으로 깊어짐에 따라 더욱 심각 -> **학습을 방해하는 요인**으로 작용
- **배치 정규화**(batch normalization)
    - 공변량 시프트 현상을 누그러뜨리기 위해 **정규화를 층 단위로 적용**하는 기법
        - $x_i^{new} = {x_i^{old} - \mu_i \above 1pt \sigma_i}$
    - 정규화를 적용하는 곳이 중요
        - 위 식을 어디에 적용할 것인가?(적용위치)
            - $z = w^T\widetilde{x} + b$
            - $y = \tau(z)$
        - 입력 또는 중간결과 중 어느 것에 적용? -> **중간결과에 적용하는 것이 유리. 액티베이션함수를 통과하기 이전.**
    - 훈련집합 전체 또는 미니배치 중 어느 것에 적용?(**적용단위**)
        - **미니배치에 적용하는 것이 유리**
- 배치 정규화 과정
    1. 미니배치 단위로 평균($\mu$)과 분산($\sigma$) 계산
    2. 구한 평균과 분산을 통해 정규화
    3. 비례($\gamma$)와 이동($\beta$) 세부 조정
- 배치 정규화 장점
    - 신경망의 경사도 흐름 개선
    - 높은 학습률 허용
    - 초기화에 대한 의존성 감소
    - 의도하지 않았지만 규제와 유사한 행동을 하며, 드롭아웃의 필요성을 감소시킴
<br>
<br>

## 배치 정규화
- 정규화 변환을 수행하는 코드
    - 미니배치에 $x_i^{new} = {x_i^{old} - \mu_i \above 1pt \sigma_i}$를 적용하여 코드1을 수행
    - 즉, **미니배치 단위**로 **노드마다 독립적으로** 코드1을 **수행**
    - **비례($\gamma$)와 이동($\beta$)**는 노드마다 고유한 매개변수로서 **학습으로 알아냄**
    - 코드1:
        - 미니배치 평균 구하기
        - 미니배치 분산 구하기
        - 정규화하기
        - 비례(scale)와 이동(shift)구하기
- 최적화를 마친 후 추가적인 **후처리 작업** 필요
    - **각 노드**는 **전체 훈련집합**을 가지고 **독립적으로** 코드2를 수행
    - 코드2:
        - 배치단위의 평균과 분산들을 다시한번 평균 내기
        - 노드에 평균, 분산, 비례, 이동 저장하기(예측 단계에서 아래 식의 변환을 수행하기 위함)
- 예측 단계
    - 각 노드는 독립적으로 식을 적용하여 변환(코드1의 마지막 두 라인을 수행하는 셈)
    - $z' = {\gamma \above 1pt \sqrt{\sigma^2 + \varepsilon}}z + (\beta - {\gamma \mu \above 1pt \sqrt{\sigma^2 + \varepsilon}})$
<br>

- CNN에서는 노드 단위가 아니라 **특징 맵 단위**로 코드1과 코드2를 적용
    - 예를 들면, 특징 맵(피쳐맵)의 크기가 p * q라면 미니배치에 있는 샘플마다 pq개의 값이 발생. 코드 1은 총 pqm개의 값을 가지고 $\mu_B$와 $\sigma_B^2$를 계산. 비례($\gamma$)와 이동($\beta$)은 특징 맵마다 하나씩 존재.
- 배치 정규화의 긍정적 효과를 측정한 실험사례
    - 가중치 초기화에 덜 민감함
    - 학습률을 크게 하여 수렴 속도 향상 가능
    - sigmoid 활성함수로 사용하는 깊은 신경망도 학습이 이루어짐
    - 규제 효과를 제공하여 드롭아웃을 적용하지 않아도 높은 성능
<br>
<br>

# 규제의 필요성과 원리
- 과잉적합에 빠지는 이유와 과잉적합을 피하는 전략
- 규제의 정의
<br>
<br>

## 과잉적합에 빠지는 이유와 과잉적합(오버피팅)을 피하는 전략
- **학습 모델의 용량**에 따른 **일반화 능력**
- 대부분 가지고 있는 데이터에 비해 훨씬 **큰 용량의 모델**을 사용
    - VGGNet은 분류층(Fully Connected)에 1억 2천 1백만 개의 매개변수를 가짐(매개변수가 많다 = 용량이 크다)
    - 훈련집합을 단순히 '암기'하는 **과잉적합(오버피팅)에 주의**를 기울여야 함
- 현대 기계 학습의 전략
    - 충분히 **큰 용량의 모델을 설계**한 다음, **학습 과정에서 여러 규제 기법을 적용**
<br>
<br>

## 규제의 정의
- 규제는 오래 전부터 수학과 통계학에서 연구해온 주제
    - **모델 용량에 비해 데이터가 부족한 경우**의 부족조건문제를 푸는 접근법
    - 적절한 가정을 투입하여 문제를 품 -> '입력과 출력 사이의 변환은 매끄럽다'는 사전 지식
        - 유사한 데이터는 가깝게 매핑된다.
    - 대표적인 티호노프의 규제기법은 **매끄러움 가정**에 기반을 둔다.
        - 규제를 적용한 목적함수 = 목적함수 + 람다*규제항
        - 통계에서는 릿지 회귀, 기계학습에서는 가중치 감쇄 등이 대표적임
- 현대 기계 학습도 매끄러움 가정을 널리 사용함
    - 가중치 감쇠 기법 : 모델의 구조적 용량을 충분히 크게 하고, '수치적 용량'을 제한하는 규제 기법
    - 비지도 학습 : 구조에 특화되어있음.
- "Deep Learning"책의 정의 : **일반화 오류를 줄이려는 의도**를 가지고 **학습 알고리즘을 수정**하는 모든 방법
<br>
<br>

# 규제 기법
- 가중치 벌칙
- 조기 멈춤
- 데이터 확대
- 드롭 아웃
- 앙상블 기법
- 명시적 규제와 암시적 규제
    - 명시적 규제: 가중치 감쇠나 드롭아웃처럼 목적함수나 신경망 구조를 **직접 수정**하는 방식
    - 암시적 규제: 조기 멈춤, 데이터 증대, 잡음 추가, 앙상블처럼 **간접적으로 영향**을 미치는 방식
<br>
<br>

## 가중치 벌칙
- 티호노프의 규제기법에서
    - $J_{regularized}(\Theta;X,Y) = J(\Theta;X,Y) + \lambda R(\Theta)$
    - 규제를 적용한 목적함수 = 목적함수 + 람다*규제항
    - **규제항**은 훈련집합과 무관하며, **데이터 새성 과정에 내재한 사전 지식에 해당**
    - 규제항은 매개변수를 작은 값으로 유지하므로 **모델의 용량을 제한하는 역할**(수치적 용량을 제한함)
        - 1차는 언더피팅되고, 10차는 오버피팅되던 것을 기억하라!
- 규제항 $R(\Theta)$로 **무엇을 사용**할 것인가?
    - 큰 가중치에 벌칙을 가해 **작은 가중치를 유지**하려고 주로 L2놈이나 L1놈을 사용
    - 규제항은 작은 가중치를 쓰기 위해 하는 것이다. 예를 들어 10차는 오버피팅 되므로 8차까지만 발현되게 하는 것이다.
<br>

- **L2놈(norm)**
    - 규제 항 R로 L2놈을 사용하는 규제 기법을 '가중치 감쇠'라 부름
    - $J_{regularized}(\Theta;X,Y) = J(\Theta;X,Y) + \lambda \left \| \Theta \right \|_{2}^{2}$
    - 위 식의 경사도 계산
        - $J_{regularized}(\Theta;X,Y) = \bigtriangledown J(\Theta;X,Y) + 2 \lambda \Theta$
    - $J_{regularized}(\Theta;X,Y) = \bigtriangledown J(\Theta;X,Y) + 2 \lambda \Theta$를 이용하여 매개변수를 갱신하는 수식
        - $\Theta = (1-2\rho \lambda)\Theta - \rho\bigtriangledown J$
    - 가중치 감쇠는 단지 $\Theta$에 $(1 - 2 \rho \lambda) = 0.96$
    - 최종해를 원점 가까이 당기는 효과(즉, **가중치를 작게 유지함**) = 가중치 감쇠(decay) 효과
<br>

- 선형회귀(linear regression)에 적용
    - 선형 회귀는 훈련집합이 주어지면 다음 식을 풀어 w를 구하는 문제이다.
    - $w_1x_{i1} + w_2x_{i2} + ... + w_dx_{id} = x_i^Tw = y_i$
    - 위 식을 행렬식으로 바꿔 쓰면,
        - $Xw = y$
    - 가중치 감쇠를 적용한 목적함수
        - $J_regularized(w) = \left \| Xw - y \right \|_{2}^{2} + \lambda\left \| w \right \|_{2}^{2} = (Xw - y)^T(Xw - y) + \lambda\left \| w \right \|_{2}^{2}$
        - L1규제 - Lasso regression
        - L2규제 - Ridge regression
    - 위 식을 미분하여 0으로 놓은 뒤 w에 대해 정리하면
        - $\widehat{w} = (X^TX + 2\lambda I)^{-1}X^Ty$
        - 공분산 행렬 $X^TX$의 대각 요소가 $2\lambda$만큼씩 증가 -> 역행렬을 곱하므로 가중치를 축소하여 원점으로 당기는 효과
    - 예측 단계에서는 $y = x^T\widehat{w}$
<br>

- **L1놈**
    - 규제 항으로 L1놈을 적용하면, 
        - $J_regularized(w) = J(\Theta; X, Y) + \lambda\left \| \Theta \right \|_1$
    - 미분하면,
        - $J_regularized(w) = \bigtriangledown J(\Theta; X, Y) + \lambda sign(\Theta)$
    - 매개변수를 갱신하는 식에 대입하면,
        - $\Theta = \Theta - \rho \bigtriangledown J(\Theta; X, Y) - \rho \lambda sign(\Theta)$
    - 매개변수를 갱신하는 식
        - $\Theta = \Theta - \rho \bigtriangledown J - \rho \lambda sign(\Theta)$
    - L1놈의 **희소성(sparsity) 효과(0이 되는 매개변수가 많음)**
        - 선형 회귀에 적용하면 **특징 선택 효과**
<br>

- 규제
    - $J_{regularized}(\Theta;X,Y) = J(\Theta;X,Y) + \lambda R(\Theta)$
    - 규제를 적용한 목적함수 = 목적함수 + 람다*규제항
    - 목적함수: 적용된 충분한 학습 모델로 훈련집합의 예측한 오차
    - 규제: 학습 모델이 훈련집합의 예측을 너무 잘 수행하지 못하도록 방지
- 효과
    - 가중치에 대한 선호도 표현
    - 학습 모델을 단순화시킴으로 일반화 성능 향상 시킴
    - 매끄럽게 하여 최적화 개선
- 대표적인 예
    - L2 규제: $R(W) = \sum_{k}\sum_{l}W_{k,l}^2$
    - L1 규제: $R(W) = \sum_{k}\sum_{l}\left | W_{k,l} \right |$
    - 엘라스틱 넷: $R(W) = \sum_{k}\sum_{l} \beta W_{k, l}^2 + \left | W_{k,l} \right |$, (L1+L2)
- 과잉적합 방지하는 가장 확실한 방법은 큰 훈련집합 사용
    - 하지만 데이터 수집은 비용이 많이 드는 작업
- 데이터 확대라는 규제 기법
    - 데이터를 **인위적으로 변형하여 확대함**
    - 자연계에서 벌어지는 잠재적인 변형을 프로그램으로 흉내내는 셈
- 예: 모핑을 이용한 변형
    - 비선형 변환으로서 아핀 변환에 비해 훨씬 다양한 형태의 확대
    - 학습 기반: 데이터에 맞는 '비선형 변환 규칙을 학습'하는 셈
