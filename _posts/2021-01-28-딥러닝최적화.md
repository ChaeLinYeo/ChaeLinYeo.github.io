---
title : "[Deep Learning: 신경망의 기초]Deep Learning 최적화"
data : 2021-01-28 00:15:28 -0400
categories : 프로그래머스인공지능스쿨
use_math: true
---
# 심층학습 최적화
## 활성함수
- 선형 연산 결과인 활성값 $z$에 비선형 활성함수 $\tau$를 적용하는 과정(은닉층에서 일어남)
- 활성함수 변천사
    - 선형 -> 계단 -> tanh -> ReLU
    - sigmoid 함수는 활성값이 커지면 포화 상태가 되고 경사도가 0에 가까운 값을 출력함 -> **매개변수 갱신(학습)이 매우 느린 요인**
<br>

- **ReLU(Rectified Linear Unit) 활성함수**
    - 경사도 포화(gradient saturation) 문제 해소
        - 0을 기점으로 해서 그 이전것은 0이고, 0 이후부터는 linear하게 자기자신을 내보냄.
        - $z = w^T\widetilde{x} + b$
        - $y = ReLU(z) = max(0, z)$
            - 0과 자기 값을 비교해서 자기 값이 0보다 작으면 0을 출력, 자기 값이 0보다 크면 그대로 출력
    - ReLU의 변형
        - Leaky ReLU(보통 $\alpha = 0.01$을 사용) : 자기자신 z가 0보다 크면 0 z 출력, 0보다 작은 경우 $\alpha z$ 출력
        - Parametric ReLU($\alpha$를 학습으로 알아냄)
<br>

- 다양한 활성함수들
    - Sigmoid
    - tanh
    - ReLU
    - Leaky ReLU
    - Maxout
    - ELU
- 최근의 활성 함수들은 다음의 문제들을 해결하고자 함
    - 포화된 영역이 경사도가 작아짐
    - 출력값이 영 중심 아님
    - 다소 높은 연산량
<br>
<br>

## 배치 정규화
- **공변량 변화(covariate shift)** 현상
    - 훈련집합과 테스트집합의 분포가 다름
    - 내부의 공변량 변화(internal covariate shift)
        - 학습이 진행되면서 첫번째 층의 매개변수가 바뀜에 따라 바뀜 -> 두번째 층 입장에서 보면 자신에게 입력되는 **데이터의 분포가 수시로 바뀌는 셈**
        - 층2, 층3, ... 으로 깊어짐에 따라 더욱 심각 -> **학습을 방해하는 요인**으로 작용
- **배치 정규화**(batch normalization)
    - 공변량 시프트 현상을 누그러뜨리기 위해 **정규화를 층 단위로 적용**하는 기법
        - $x_i^{new} = {x_i^{old} - \mu_i \above 1pt \sigma_i}$
    - 정규화를 적용하는 곳이 중요
        - 위 식을 어디에 적용할 것인가?(적용위치)
            - $z = w^T\widetilde{x} + b$
            - $y = \tau(z)$
        - 입력 또는 중간결과 중 어느 것에 적용? -> **중간결과에 적용하는 것이 유리. 액티베이션함수를 통과하기 이전.**
    - 훈련집합 전체 또는 미니배치 중 어느 것에 적용?(**적용단위**)
        - **미니배치에 적용하는 것이 유리**
- 배치 정규화 과정
    1. 미니배치 단위로 평균($\mu$)과 분산($\sigma$) 계산
    2. 구한 평균과 분산을 통해 정규화
    3. 비례($\gamma$)와 이동($\beta$) 세부 조정
- 배치 정규화 장점
    - 신경망의 경사도 흐름 개선
    - 높은 학습률 허용
    - 초기화에 대한 의존성 감소
    - 의도하지 않았지만 규제와 유사한 행동을 하며, 드롭아웃의 필요성을 감소시킴
<br>
<br>

## 배치 정규화
- 정규화 변환을 수행하는 코드
    - 미니배치에 $x_i^{new} = {x_i^{old} - \mu_i \above 1pt \sigma_i}$를 적용하여 코드1을 수행
    - 즉, **미니배치 단위**로 **노드마다 독립적으로** 코드1을 **수행**
    - **비례($\gamma$)와 이동($\beta$)**는 노드마다 고유한 매개변수로서 **학습으로 알아냄**
    - 코드1:
        - 미니배치 평균 구하기
        - 미니배치 분산 구하기
        - 정규화하기
        - 비례(scale)와 이동(shift)구하기
- 최적화를 마친 후 추가적인 **후처리 작업** 필요
    - **각 노드**는 **전체 훈련집합**을 가지고 **독립적으로** 코드2를 수행
    - 코드2:
        - 배치단위의 평균과 분산들을 다시한번 평균 내기
        - 노드에 평균, 분산, 비례, 이동 저장하기(예측 단계에서 아래 식의 변환을 수행하기 위함)
- 예측 단계
    - 각 노드는 독립적으로 식을 적용하여 변환(코드1의 마지막 두 라인을 수행하는 셈)
    - $z' = {\gamma \above 1pt \sqrt{\sigma^2 + \varepsilon}}z + (\beta - {\gamma \mu \above 1pt \sqrt{\sigma^2 + \varepsilon}})$
<br>

- CNN에서는 노드 단위가 아니라 **특징 맵 단위**로 코드1과 코드2를 적용
    - 예를 들면, 특징 맵(피쳐맵)의 크기가 p * q라면 미니배치에 있는 샘플마다 pq개의 값이 발생. 코드 1은 총 pqm개의 값을 가지고 $\mu_B$와 $\sigma_B^2$를 계산. 비례($\gamma$)와 이동($\beta$)은 특징 맵마다 하나씩 존재.
- 배치 정규화의 긍정적 효과를 측정한 실험사례
    - 가중치 초기화에 덜 민감함
    - 학습률을 크게 하여 수렴 속도 향상 가능
    - sigmoid 활성함수로 사용하는 깊은 신경망도 학습이 이루어짐
    - 규제 효과를 제공하여 드롭아웃을 적용하지 않아도 높은 성능
<br>
<br>

# 규제의 필요성과 원리
- 과잉적합에 빠지는 이유와 과잉적합을 피하는 전략
- 규제의 정의
<br>
<br>

## 과잉적합에 빠지는 이유와 과잉적합(오버피팅)을 피하는 전략
- **학습 모델의 용량**에 따른 **일반화 능력**
- 대부분 가지고 있는 데이터에 비해 훨씬 **큰 용량의 모델**을 사용
    - VGGNet은 분류층(Fully Connected)에 1억 2천 1백만 개의 매개변수를 가짐(매개변수가 많다 = 용량이 크다)
    - 훈련집합을 단순히 '암기'하는 **과잉적합(오버피팅)에 주의**를 기울여야 함
- 현대 기계 학습의 전략
    - 충분히 **큰 용량의 모델을 설계**한 다음, **학습 과정에서 여러 규제 기법을 적용**
<br>
<br>

## 규제의 정의
- 규제는 오래 전부터 수학과 통계학에서 연구해온 주제
    - **모델 용량에 비해 데이터가 부족한 경우**의 부족조건문제를 푸는 접근법
    - 적절한 가정을 투입하여 문제를 품 -> '입력과 출력 사이의 변환은 매끄럽다'는 사전 지식
        - 유사한 데이터는 가깝게 매핑된다.
    - 대표적인 티호노프의 규제기법은 **매끄러움 가정**에 기반을 둔다.
        - 규제를 적용한 목적함수 = 목적함수 + 람다*규제항
        - 통계에서는 릿지 회귀, 기계학습에서는 가중치 감쇄 등이 대표적임
- 현대 기계 학습도 매끄러움 가정을 널리 사용함
    - 가중치 감쇠 기법 : 모델의 구조적 용량을 충분히 크게 하고, '수치적 용량'을 제한하는 규제 기법
    - 비지도 학습 : 구조에 특화되어있음.
- "Deep Learning"책의 정의 : **일반화 오류를 줄이려는 의도**를 가지고 **학습 알고리즘을 수정**하는 모든 방법
<br>
<br>

# 규제 기법
- 가중치 벌칙
- 조기 멈춤
- 데이터 확대
- 드롭 아웃
- 앙상블 기법
- 명시적 규제와 암시적 규제
    - 명시적 규제: 가중치 감쇠나 드롭아웃처럼 목적함수나 신경망 구조를 **직접 수정**하는 방식
    - 암시적 규제: 조기 멈춤, 데이터 증대, 잡음 추가, 앙상블처럼 **간접적으로 영향**을 미치는 방식
<br>
<br>

## 가중치 벌칙
- 티호노프의 규제기법에서
    - $J_{regularized}(\Theta;X,Y) = J(\Theta;X,Y) + \lambda R(\Theta)$
    - 규제를 적용한 목적함수 = 목적함수 + 람다*규제항
    - **규제항**은 훈련집합과 무관하며, **데이터 새성 과정에 내재한 사전 지식에 해당**
    - 규제항은 매개변수를 작은 값으로 유지하므로 **모델의 용량을 제한하는 역할**(수치적 용량을 제한함)
        - 1차는 언더피팅되고, 10차는 오버피팅되던 것을 기억하라!
- 규제항 $R(\Theta)$로 **무엇을 사용**할 것인가?
    - 큰 가중치에 벌칙을 가해 **작은 가중치를 유지**하려고 주로 L2놈이나 L1놈을 사용
    - 규제항은 작은 가중치를 쓰기 위해 하는 것이다. 예를 들어 10차는 오버피팅 되므로 8차까지만 발현되게 하는 것이다.
<br>

- **L2놈(norm)**
    - 가중치 벡터에 L2놈을 사용하는 것은 그 벡터(가중치)의 크기를 재는 것이다.
    - 규제 항 R로 L2놈을 사용하는 규제 기법을 '가중치 감쇠'라 부름
    - $J_{regularized}(\Theta;X,Y) = J(\Theta;X,Y) + \lambda \left \| \Theta \right \|_{2}^{2}$
    - 위 식의 경사도 계산
        - $J_{regularized}(\Theta;X,Y) = \bigtriangledown J(\Theta;X,Y) + 2 \lambda \Theta$
    - $J_{regularized}(\Theta;X,Y) = \bigtriangledown J(\Theta;X,Y) + 2 \lambda \Theta$를 이용하여 매개변수를 갱신하는 수식
        - $\Theta = (1-2\rho \lambda)\Theta - \rho\bigtriangledown J$
    - 가중치 감쇠는 단지 $\Theta$에 $(1 - 2 \rho \lambda) = 0.96$
    - 최종해를 원점 가까이 당기는 효과(즉, **가중치를 작게 유지함**) = 가중치 감쇠(decay) 효과
<br>

- 선형회귀(linear regression)에 적용
    - 선형 회귀는 훈련집합이 주어지면 다음 식을 풀어 w를 구하는 문제이다.
    - $w_1x_{i1} + w_2x_{i2} + ... + w_dx_{id} = x_i^Tw = y_i$
    - 위 식을 행렬식으로 바꿔 쓰면,
        - $Xw = y$
    - 가중치 감쇠를 적용한 목적함수
        - $J_regularized(w) = \left \| Xw - y \right \|_{2}^{2} + \lambda\left \| w \right \|_{2}^{2} = (Xw - y)^T(Xw - y) + \lambda\left \| w \right \|_{2}^{2}$
        - L1규제 - Lasso regression(규제항으로 L1놈을 썼을 때)
        - L2규제 - Ridge regression(규제항으로 L2놈을 썼을 때)
    - 위 식을 미분하여 0으로 놓은 뒤 w에 대해 정리하면
        - $\widehat{w} = (X^TX + 2\lambda I)^{-1}X^Ty$
        - 공분산 행렬 $X^TX$의 대각 요소가 $2\lambda$만큼씩 증가 -> 역행렬을 곱하므로 가중치를 축소하여 원점으로 당기는 효과
    - 예측 단계에서는 $y = x^T\widehat{w}$
<br>

- **L1놈**
    - L2놈은 루트에 제곱한 것, L1놈은 크기에 절대값을 씌운 것
    - 규제 항으로 L1놈을 적용하면, 
        - $J_regularized(w) = J(\Theta; X, Y) + \lambda\left \| \Theta \right \|_1$
    - 미분하면,
        - $J_regularized(w) = \bigtriangledown J(\Theta; X, Y) + \lambda sign(\Theta)$
    - 매개변수를 갱신하는 식에 대입하면,
        - $\Theta = \Theta - \rho \bigtriangledown J(\Theta; X, Y) - \rho \lambda sign(\Theta)$
    - 매개변수를 갱신하는 식
        - $\Theta = \Theta - \rho \bigtriangledown J - \rho \lambda sign(\Theta)$
    - L1놈의 **희소성(sparsity) 효과(0이 되는 매개변수가 많음)**
        - 선형 회귀에 적용하면 **특징 선택 효과**
<br>

- 비유하자면 다음과 같다.
    - L2놈 : 1, 1, 1을 1/2, 1/2, 1/2로 만드는 것. 보통 L2놈을 많이 쓴다. 
    - L1놈 : 1, 1, 1을 0, 0, 1로 만드는 것. 의미를 찾거나 특징을 selection할 때 주로 쓴다.

- 규제
    - $J_{regularized}(\Theta;X,Y) = J(\Theta;X,Y) + \lambda R(\Theta)$
    - 규제를 적용한 목적함수 = 목적함수 + 람다*규제항
    - 람다는 규제를 얼마나 줄 지에 대한 "선호도"이다.
    - 목적함수: 적용된 충분한 학습 모델로 훈련집합의 예측한 오차
    - 규제: 학습 모델이 훈련집합의 예측을 너무 잘 수행하지 못하도록 방지(오버피팅 방지)
- 효과
    - 가중치에 대한 선호도 표현(가중치에 대해 얼마나 자유도를 줄 것인지 조절)
    - 학습 모델을 단순화시킴으로 일반화 성능 향상 시킴
    - 매끄럽게 하여 최적화 개선
- 대표적인 예
    - L2 규제: $R(W) = \sum_{k}\sum_{l}W_{k,l}^2$
    - L1 규제: $R(W) = \sum_{k}\sum_{l}\left | W_{k,l} \right |$
    - 엘라스틱 넷(L1, L2놈을 적절하게 섞은 것): $R(W) = \sum_{k}\sum_{l} \beta W_{k, l}^2 + \left | W_{k,l} \right |$, (L1+L2)
<br>
<br>

## 조기 멈춤
- 학습 시간에 따른 일반화 능력
    - 일정 시간이 지나면 과잉적합(오버피팅) 현상이 나타남 -> 일반화 능력이 저하됨.
    - 즉 훈련 데이터를 단순히 암기하기 시작.
- **조기 멈춤**(early stopping) 규제기법
    - 검증집합의 오류가 최저인 점에서 학습을 멈춘다.
<br>
<br>

## 데이터 확대
- 과잉적합 방지하는 가장 확실한 방법은 큰 훈련집합 사용
    - 하지만 데이터 수집은 비용이 많이 드는 작업
- 데이터 확대 규제 기법
    - 데이터를 **인위적으로 변형하여 확대함** : 아핀 변환(이동, 회전, 반전)
    - 자연계에서 벌어지는 잠재적인 변형을 프로그램으로 흉내내는 셈
- 한계: 아핀 변환은 수작업 변형, 모든 부류가 같은 변형 사용-> 이를 해결하기 위해 아래와 같은 변형들이 나옴.
- 예: 모핑을 이용한 변형
    - 비선형 변환으로서 아핀 변환에 비해 훨씬 다양한 형태의 확대
    - 학습 기반: 데이터에 맞는 '비선형 변환 규칙을 학습'하는 셈
- 예: 자연영상 확대
    - 영상을 잘라내어 이동 효과, 좌우 반전
    - PCA로 색상변환
    - 예측 단계에서 잘라내고 좌우반전하여 앙상블 적용
- 예: 잡음을 섞어 확대
    - 입력 데이터에 잡음 섞기
    - 은닉 노드에 잡음을 섞기
<br>
<br>

## 드롭아웃
- 드롭아웃(dropout) 규제 기법
    - 완전연결층의 노드 중 일정 비율(일반적으로 p=0.5 적용)을 임의 선택하여 제거 -> 남은 부분 신경망 학습
    - 완전연결의 단점: 오버피팅 -> 드롭아웃으로 dense한 것을 sparse하게 만듦으로써 오버피팅 방지. 가중치들이 서로 비슷하게 동기화되어 학습되지 않고 특징별로 의미가 두드러지게 학습될 수 있음.(의미들이 세분화되고 부각됨)
    - 많은 부분 신경망을 만들고, 앙상블 결합하는 기법
- 요즘엔 드롭아웃보다는 배치 노말라이제이션을 많이 쓴다.
<br>

- 신경망의 완전연결층(FC)에 드롭아웃 적용 알고리즘
- 입력: 드롭아웃 비율 $p_{input}, p_{hidden}$
- 출력: 최적해 $\Theta$
- 난수를 생성하여 초기해 $\Theta$를 설정한다.
- while(! 멈춤조건) // 수렴조건
    - 미니배치 B를 샘플링한다.
    - for(i=1 to |B|)   // B의 샘플 각각에 대해
        - 입력층은 $p_{input}$, 은닉층은 $p_{hidden}$ 비율로 드롭아웃을 수행한다.
        - 드롭아웃된 부분 신경망 $\Theta_i^{dropout}$로 전방 계산을 한다.
        - 오류 역전파를 이용하여 $\Theta_i^{dropout}$를 위한 그레디언트 $\bigtriangledown_i^{dropout}$를 구한다.
    - 그레디언트들의 평균 $\bigtriangledown_{ave}^{dropout}$를 계산한다.
    - $\Theta = \Theta - \rho \bigtriangledown_{ave}^{dropout}$ // 가중치 갱신
- $\widehat{\Theta} = \Theta$
<br>

- 일반적으로 입력층 제거 비율 0.2, 은닉층 제거 비율 0.5로 설정
<br>

- 예측 단계
    - 앙상블 효과 모방 
        - 학습 과정에서 가중치가(1-드롭아웃 비율)만큼만 참여했기 때문에 p만큼 보정
- 메모리와 계산 효율
    - 추가 메모리는 참거짓 배열 $\pi$, 추가 계산은 작음
    - 실제 부담은 신경망의 크기에서 옴: 보통 은닉 노드 수를 $1 \above 1pt P_{hidden}$만큼 늘림
<br>
<br>

## 앙상블 기법
- 앙상블(ensemble)
    - 서로 다른 여러 개의 모델을 결합하여 일반화 오류를 줄이는 기법
    - 현대 기계학습은 앙상블도 규제로 여김
- 두 가지 일
    1. 서로 다른 예측기를 학습하는 일
        - 서로 다른 구조의 신경망 여러 개를 학습 또는 같은 구조를 사용하지만 서로 다른 초기값과 하이퍼 매개변수를 설정하고 학습
            - **배깅**(bagging, bootstrap aggregating): 훈련집합을 여러 번 샘플링하여(복원추출) 서로 다른 훈련집합을 구성. 동시다발적으로 학습.
            - **부스팅**(boosting): i번째 예측기가 틀린 샘플을 i+1번째 예측기가 잘 인식하도록 연계성을 고려. 순차적으로 학습하여 서로 상호보완적인 관계가 되도록함.
    2. 학습된 예측기를 결합하는 일 -> 모델 평균(model average)
        - 여러 모델의 출력에서 평균을 구하거나 투표하여 최종 결과 결정
<br>
<br>

## 하이퍼 매개변수 최적화
- 학습 모델에는 두 종류의 매개변수가 있음
    - 내부 매개변수(parameter) 혹은 가중치(weight)
        - 신경망의 경우, 가중치 $\Theta$fh vyrl
        - 학습 알고리즘이 최적화함
            - 주어진 데이터로부터 결정됨
    - 하이퍼 매개변수(hyper-parameter)
        - 모델의 외부에서 모델의 동작을 조정함
            - 사람에 의해서 결정됨
        - 예: 은닉층의 개수, CNN의 필터 크기와 epoch, 학습률 등
<br>

- 하이퍼 매개변수 선택
    - 표준 참고 문헌이 제시하는 기본값을 사용하면 됨
        - 보토 여러 후보 값 또는 범위를 제시
    - 후보 값 중에서 주어진 데이터에 최적인 값 선택 <- 하이퍼 매개변수 최적화
- 하이퍼 매개변수 조합 생성을 구현하는 방법에 따라 수동탐색, 격자탐색, 임의 탐색
    - 최근 학습을 통한 자동 탐색 방법들이 연구됨(자동화된 기계학습)
<br>
<br>

- 격자 탐색(grid search)과 임의 탐색(random search)
    - 격자탐색은 격자모양으로 나눴을 때 교차점들에 위치한 것들을 탐색.
    - 임의 탐색은 난수로 하이퍼 매개변수 조합을 생성함. 격자 탐색보다 임의 탐색이 좋다.
- 로그 공간(log space) 간격으로 탐색
    - 어떤 하이퍼 매개변수는 로그 공간을 사용해야 함
    - 학습률 범위가 있을 때 로그 공간 간격은 등 간격보다 2배 증가된 간격으로 공간을 조사한다.
<br>

- 차원의 저주 문제 발생
    - 차원의 저주: 고차원이 될수록 그 안에서 의미있는 값을 찾기 위해서는 더 많은 데이터가 필요하다.
    - 매개변수가 $m$개이고 각각이 $q$개 구간이라면 $q^m$개의 점을 조사해야 함
- 임의 탐색이 우월함
    - 크게 하면서 경향성을 찾은 뒤 점차 세밀해지는 coarse-fine 탐색
<br>
<br>

# 2차 미분을 이용한 최적화 방법
- 뉴턴 방법
- 켤레 경사도 방법
- 유사 뉴턴 방법
<br>
<br>

- 1차 미분을 사용하는 경사 하강법
    - 현재 기계 학습의 주류 알고리즘
    - 두 가지 개선책
        - 경사도의 잡음을 줄임(미니배치, 모멘텀 사용 등)
        - 2차 미분 정보를 활용
- 2차미분 방법보다는 1차미분 방법이 더 많이 쓰임! 아직 가야할 길이 멀다~ 하지만 1차 민분보다 효과적일 수 있는 가능성은 열려있다!
<br>

- 경사 하강법을 더 빠르게 할 수 있나?
    - 1차 미분 정보로는 경사 하강법으로 해를 찾아가는 최단 직선 경로를 알 수 없음. 1차 미분은 현재 위치에서 지역적인 기울기 정보만 주기 때문. -> 뉴턴 방법(newton method)은 2차 미분 정보를 활용하여 사 하강법으로 해를 찾아가는 최단 직선 경로를 알아냄.
<br>

- 1차 미분 최적화와 2차 미분 최적화 비교
    - 1차 미분의 최적화
        - 경사도 사용하여 선형 근사 사용
        - 근사치 최소화
    - 2차 미분의 최적화
        - 경사도와 헤시안을 사용하여 2차 근사(2차 함수가 근사함수가 됨) 사용
        - 근사치의 최소값
<br>
<br>

## 뉴턴 방법
- 테일러 급수: 주어진 함수를 정의역에서 특정 점의 미분계수들을 계수로 가지는 다항식의 극한(멱급수)으로 표현함
- 테일러 급수를 적용하여 델타로 미분하면,
    - $w+\delta$를 최소점이라 가정하면, ${\partial J(w + \delta) \above 1pt \partial \delta} \approx J'(w) + \delta J''(w) = 0$
- 식을 조금 정리하면, 
    - $\delta = -{J'(w) \above 1pt J''(w)} = -(J''(w))^{-1}J'(w)$
- 변수가 여러 개인 경우로 확장하면,
    - $\delta = -H^{-1}\bigtriangledown J$
<br>
<br>

## 켤레 경사도 방법
- 직선 탐색(line search): 이동 크기를 결정하기 위해 직선으로 탐색하고, 미분
    - 원래의 경사하강법의 직선탐색: 현재 점에서부터 2차로 근사화할때 근사하는 범위를 직선의 형태를 통해서 탐색하고, 이동할 크기(근사할 크기)에 따라 이동
    - 켤레 경사도 방법(conjugate gradient method): 직전 정보를 사용하여 해에 빨리 접근. 이전에 썼던 방향과 현재의 방향 두가지를 이용해 새로운 방향을 찾고 근사한다. 뉴턴 방법에 비해 훨씬 빠르게 근사할 수 있다.
<br>
<br>

## 유사 뉴턴 방법
- 유사 뉴턴 방법(quasi-Newton methods)의 기본 개념
    - 문제점
        - 경사 하강법: 수렴 효율성 낮음
        - 뉴턴 방법: 헤시안 행렬 연산 부담 -> 헤시안 H의 역행렬을 근사하는 행렬 M을 사용
    - 대표적으로 점진적으로 헤시안을 근사화하는 LFGS가 많이 사용됨
    - 기계 학습에서는 M을 저장하는 메모리를 적게 쓰는 **L-BFGS를 주로 사용함**
        - 전체 배치를 통한 갱신을 할 수 있다면, L-BFGS 사용을 고려함
- 기계 학습에서 2차 미분 정보의 활용
    - 현재 널리 활용되지는 않지만 연구 계속되고 있음
<br>
<br>

