---
title : "[Big Data]Spark4"
data : 2021-02-05 00:15:28 -0400
categories : 프로그래머스인공지능스쿨
use_math: true
---
# Spark MLlib 모델 튜닝: Spark MLlib가 제공해주는 모델 튜닝에 대해 배워보자
## Spark MLlib 모델 튜닝 (ML Tuning)
- 최적의 하이퍼 파라미터를 선택하는 것
    - 최적의 모델 혹은 모델의 파라미터를 찾는 것이 아주 중요
    - epoch, 학습률, decision tree의 최대 깊이 등이 하이퍼 파라미터가 될 수 있다.
    - 하나씩 테스트해보는 것 vs. 다수를 동시에 테스트하는 것
    - 모델 선택의 중요한 부분은 테스트 방법
        - 교차 검증(Cross Validation)과 홀드 아웃(Train-Validation Split) 테스트 방법을 지원
    - 보통 ML Pipeline과 같이 사용함.
<br>

## Spark MLlib 모델 테스트
- 모델 테스트 방법: 크게 2가지가 존재
    - 교차 검증(Cross Validation)
    - 훈련/테스트셋 나누기(Train-validation split): 각 셋이 편향이 고르지 않게 분배되지 않게 조심해야 한다! 이에 대한 대안이 교차검증이다. 교차검증은 train-validation split을 여러번 반복하여 여러번 훈련해 성능지표를 계산하고, 그것의 평균을 낸다.
- 훈련용과 테스트용 데이터 기반 테스트(Train & Validation Split)
    - Holdout 테스트라고 하기도 함
    - 보통 훈련과 테스트 비율을 80:20 or 75:25로 한다.
    1. 트레이닝셋을 훈련용과 테스트용으로 분리
    2. 훈련용 데이터로 모델 빌딩
    3. 테스트용 데이터로 예측값 수집
    4. 예측값과 정답값 비교
    - 문제는 훈련용과 테스트용의 밸런스가 비슷하지 않으면 만들어진 모델과 이를 테스트할때 문제가 생길 수 있다(오버피팅)
    - 이를 해결하기 위한 것이 바로 교차분석 테스트(CV)
- 교차분석 테스트(Cross Validation)
    - K-Fold 테스트라고 부르기도 함
    - 트레이닝 셋을 K개의 서브셋으로 나눠 총 K번의 훈련을 반복. 각 K를 폴드라고 부른다. 모든 폴드가 한번씩 훈련과 테스트 데이터가 되고, 최종적으로 K개의 결과에 대한 평균이 Output이 된다.
    - 홀드아웃 테스트보다 훨씬 더 안정적. 오버피팅 문제가 감소
<br>

## Spark MLlib 모델 튜닝(Tuning)
- **Cross Validation, TrainValidationSplit**
    - TrainValidationSplit: 홀드아웃 기반 테스트 수행
    - CrossValidatior: 교차분석(K-Fold) 기반 테스트 수행
    - 다음과 같은 입력을 기반으로 가장 좋은 파라미터를 찾아줌
        - Estimator: 머신러닝 모델 혹은 ML Pipeline
        - Evaluator: 머신러닝 모델의 성능을 나타내는 지표(AUC 등)
        - Parameter: 훈련 반복 회수 등의 하이퍼 파라미터
            - ParamGridBuilder를 이용해 ParamGrid 타입의 변수 생성
    - 최종적으로 가장 결과가 좋은 모델을 리턴!
<br>

## Spark MLlib 머신러닝 모델 성능 측정
- **Evaluator**: 머신러닝 모델의 성능을 나타내는 지표
    - Spark MLlib에서는 **evaluate** 함수가 제공됨
        - 인자로 테스트셋의 결과가 들어있는 데이터프레임과 파라미터가 제공
    - 머신러닝 알고리즘에 따라 다양한 Evaluator가 제공됨
        - RegressionEvaluator: 회귀모델을 쓸때 사용
        - BinaryClassificationEvaluator: 이진분류 모델을 쓸때 사용
            - AUC(Area Under the Curve)가 성능지표가 됨: AUC로 이진분류의 성능을 측정.
        - MulticlassClassificationEvaluator
        - RankingEvaluator
    - DF와 Parameter가 input으로 주어지면 Evaluator가 성능지표(Metric)를 계산한다.
        - DF: Prediction 컬럼과 테이블 컬럼이 들어있는 데이터프레임. Logistic Regression의 경우, probability 컬럼도 들어옴. 보통 이 데이터프레임은 머신러닝 모델의 transform 함수가 리턴해준 값이 됨
        - Parametor: 성능지표 이름(areaUnderROC)등등
<br>

## Spark MLlib 모델 튜닝
- 모델 선택시 입력
    - Estimator: 머신러닝 알고리즘이나 모델 빌딩 파이프라인(ML Pipeline)
    - Evaluator: 머신러닝 모델 성능 측정에 사용되는 지표(metrics)
    - 모델의 파라미터 맵
        - 파라미터 그리드. 모델 테스트시 고려해야하는 가능한 러닝 관련 파라미터들. 트리 관련 알고리즘에서 중요함
        - 테스트되는 파라미터의 예로는 트리의 최대 깊이, 훈련 횟수 등
<br>

## Spark MLlib 머신러닝 모델 빌딩 전체 프로세스
1. 데이터프레임 기반 트레이닝 셋을 ML Pipeline에 넣는다.
2. ML Pipeline은 다음과 같이 구성된다(예시)
    - Feature Transformer: 결측치를 imputer로 mean값 채우기, 성별을 0과 1로 바꾸기
    - Logistic Regression: fit 함수 사용
3. ML Pipeline을 거쳐 최종 모델이 나온다.
    - ML Pipeline과 ML Tuning(Train Validation Split, Cross Validation)클래스를 연동해서 쓸 수 있다. 
    - ML Tuning의 인자로 ML Pipeline, Evaluator, Parameter Grid가 들어오고, 이를 통해 최고의 성능을 보이는 모델을 도출할 수 있다. 
<br>
<br>

# 실습: ML Pipeline 기반 머신러닝 모델 만들기 - 타이타닉 승객 예측
## 타이타닉 승객 생존 예측 분류기 개발 방향
- 이번에는 ML Pipeline을 사용하여 모델을 빌딩
- 다양한 Transformer 사용
    - Imputer: 나이 결측치를 평균값으로 메꾸기
    - StringIndexer: 성별을 0과1로 바꾸기
    - VectorAssembler: 피쳐들을 하나로 묶기 위함
    - MinMaxScaler를 적용하여 피쳐 값을 0과 1사이로 스케일
- GBTClassifier와 LogisticRegression을 머신러닝 알고리즘으로 사용
    - Gradient Boosted Tree Classifier
        - 의사결정 트리(Decision Tree)의 머신러닝 알고리즘
        - Regression과 Classification 모두에 사용가능
- CrossValidation을 사용하여 모델 파라미터 선택
    - BinaryClassificationEvaluator를 Evaluator로 사용
    - ParamGridBuilder를 사용하여 ParamGrid를 생성
    - 뒤에 설명할 ML Pipeline을 인자로 지정
        - ML Pipeline를 만들 때 머신러닝 알고리즘을 마지막에 지정해야 함
<br>

## MinMaxScaler
- 기본적으로 VectorAssembler로 벡터 변환된(다수의 피쳐 컬럼들이 하나의 컬럼으로 벡터 형태로 들어간 것) 피쳐컬럼에 적용. 새로운 벡터 피쳐로 변환한다.
- 피쳐 값들이 0과 1사이로 스케일하도록 변환함.
- 스케일러를 적용하기 전보다 AUC의 점수가 소폭 상승할 수 있음.
<br>

## ML Pipeline 사용 절차
- 트레이닝셋에 수행해야하는 feature transformer들을 생성
- 사용하고자 하는 머신러닝 모델 알고리즘(Estimator)을 생성
- 이것들을 순서대로 파이썬 리스트에 추가
    - 머신러닝 알고리즘이 마지막으로 추가되어야 함
- 이 파이썬 리스트를 인자로 Pipeline 개체를 생성
- 이 Pipeline의 개체를 이용해 모델 빌딩: 2가지 방법 존재
    1. 이 Pipeline의 fit 함수를 호출하면서 트레이닝셋 데이터프레임을 지정해 바로 모델 생성
    2. 이 Pipeline을 ML Tuning 개체로 지정해서 여러 하이퍼 파라미터를 테스트해보고 가장 결과가 좋은 모델 선택(보통 cross-validation을 사용)
<br>

## ML Tuning 사용 절차
- 테스트하고 싶은 머신러닝 알고리즘 개체 생성(혹은 ML Pipeline)
- ParamGrid를 만들어 테스트하고 싶은 하이퍼 파라미터 지정
- CrossValidator 혹은 TrainValidationSplit 생성
    - CrossValidator에는 4가지의 인자가 필요하다. pipeline, paramGrid, evaluator, numFolds(폴드를 몇개로 나눌 것인지)
- fit 함수 호출해서 최선의 모델 선택
<br>
