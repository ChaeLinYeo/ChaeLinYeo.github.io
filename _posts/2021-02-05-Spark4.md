---
title : "[Big Data]Spark4"
data : 2021-02-05 00:15:28 -0400
categories : 프로그래머스인공지능스쿨
use_math: true
---
# Spark MLlib 모델 튜닝: Spark MLlib가 제공해주는 모델 튜닝에 대해 배워보자
## Spark MLlib 모델 튜닝 (ML Tuning)
- 최적의 하이퍼 파라미터를 선택하는 것
    - 최적의 모델 혹은 모델의 파라미터를 찾는 것이 아주 중요
    - epoch, 학습률, decision tree의 최대 깊이 등이 하이퍼 파라미터가 될 수 있다.
    - 하나씩 테스트해보는 것 vs. 다수를 동시에 테스트하는 것
    - 모델 선택의 중요한 부분은 테스트 방법
        - 교차 검증(Cross Validation)과 홀드 아웃(Train-Validation Split) 테스트 방법을 지원
    - 보통 ML Pipeline과 같이 사용함.
<br>

## Spark MLlib 모델 테스트
- 모델 테스트 방법: 크게 2가지가 존재
    - 교차 검증(Cross Validation)
    - 훈련/테스트셋 나누기(Train-validation split): 각 셋이 편향이 고르지 않게 분배되지 않게 조심해야 한다! 이에 대한 대안이 교차검증이다. 교차검증은 train-validation split을 여러번 반복하여 여러번 훈련해 성능지표를 계산하고, 그것의 평균을 낸다.
- 훈련용과 테스트용 데이터 기반 테스트(Train & Validation Split)
    - Holdout 테스트라고 하기도 함
    - 보통 훈련과 테스트 비율을 80:20 or 75:25로 한다.
    1. 트레이닝셋을 훈련용과 테스트용으로 분리
    2. 훈련용 데이터로 모델 빌딩
    3. 테스트용 데이터로 예측값 수집
    4. 예측값과 정답값 비교
    - 문제는 훈련용과 테스트용의 밸런스가 비슷하지 않으면 만들어진 모델과 이를 테스트할때 문제가 생길 수 있다(오버피팅)
    - 이를 해결하기 위한 것이 바로 교차분석 테스트(CV)
- 교차분석 테스트(Cross Validation)
    - K-Fold 테스트라고 부르기도 함
    - 트레이닝 셋을 K개의 서브셋으로 나눠 총 K번의 훈련을 반복. 각 K를 폴드라고 부른다. 모든 폴드가 한번씩 훈련과 테스트 데이터가 되고, 최종적으로 K개의 결과에 대한 평균이 Output이 된다.
    - 홀드아웃 테스트보다 훨씬 더 안정적. 오버피팅 문제가 감소
<br>

## Spark MLlib 모델 튜닝(Tuning)
- **Cross Validation, TrainValidationSplit**
    - TrainValidationSplit: 홀드아웃 기반 테스트 수행
    - CrossValidatior: 교차분석(K-Fold) 기반 테스트 수행
    - 다음과 같은 입력을 기반으로 가장 좋은 파라미터를 찾아줌
        - Estimator: 머신러닝 모델 혹은 ML Pipeline
        - Evaluator: 머신러닝 모델의 성능을 나타내는 지표(AUC 등)
        - Parameter: 훈련 반복 회수 등의 하이퍼 파라미터
            - ParamGridBuilder를 이용해 ParamGrid 타입의 변수 생성
    - 최종적으로 가장 결과가 좋은 모델을 리턴!
<br>

## Spark MLlib 머신러닝 모델 성능 측정
- **Evaluator**: 머신러닝 모델의 성능을 나타내는 지표
    - Spark MLlib에서는 **evaluate** 함수가 제공됨
        - 인자로 테스트셋의 결과가 들어있는 데이터프레임과 파라미터가 제공
    - 머신러닝 알고리즘에 따라 다양한 Evaluator가 제공됨
        - RegressionEvaluator: 회귀모델을 쓸때 사용
        - BinaryClassificationEvaluator: 이진분류 모델을 쓸때 사용
            - AUC(Area Under the Curve)가 성능지표가 됨: AUC로 이진분류의 성능을 측정.
        - MulticlassClassificationEvaluator
        - RankingEvaluator
    - DF와 Parameter가 input으로 주어지면 Evaluator가 성능지표(Metric)를 계산한다.
        - DF: Prediction 컬럼과 테이블 컬럼이 들어있는 데이터프레임. Logistic Regression의 경우, probability 컬럼도 들어옴. 보통 이 데이터프레임은 머신러닝 모델의 transform 함수가 리턴해준 값이 됨
        - Parametor: 성능지표 이름(areaUnderROC)등등
<br>

## Spark MLlib 모델 튜닝
- 모델 선택시 입력
    - Estimator: 머신러닝 알고리즘이나 모델 빌딩 파이프라인(ML Pipeline)
    - Evaluator: 머신러닝 모델 성능 측정에 사용되는 지표(metrics)
    - 모델의 파라미터 맵
        - 파라미터 그리드. 모델 테스트시 고려해야하는 가능한 러닝 관련 파라미터들. 트리 관련 알고리즘에서 중요함
        - 테스트되는 파라미터의 예로는 트리의 최대 깊이, 훈련 횟수 등
<br>

## Spark MLlib 머신러닝 모델 빌딩 전체 프로세스
1. 데이터프레임 기반 트레이닝 셋을 ML Pipeline에 넣는다.
2. ML Pipeline은 다음과 같이 구성된다(예시)
    - Feature Transformer: 결측치를 imputer로 mean값 채우기, 성별을 0과 1로 바꾸기
    - Logistic Regression: fit 함수 사용
3. ML Pipeline을 거쳐 최종 모델이 나온다.
    - ML Pipeline과 ML Tuning(Train Validation Split, Cross Validation)클래스를 연동해서 쓸 수 있다. 
    - ML Tuning의 인자로 ML Pipeline, Evaluator, Parameter Grid가 들어오고, 이를 통해 최고의 성능을 보이는 모델을 도출할 수 있다. 
<br>
<br>

# 실습: ML Pipeline 기반 머신러닝 모델 만들기 - 타이타닉 승객 예측
## 타이타닉 승객 생존 예측 분류기 개발 방향
- 이번에는 ML Pipeline을 사용하여 모델을 빌딩
- 다양한 Transformer 사용
    - Imputer: 나이 결측치를 평균값으로 메꾸기
    - StringIndexer: 성별을 0과1로 바꾸기
    - VectorAssembler: 피쳐들을 하나로 묶기 위함
    - MinMaxScaler를 적용하여 피쳐 값을 0과 1사이로 스케일
- GBTClassifier와 LogisticRegression을 머신러닝 알고리즘으로 사용
    - Gradient Boosted Tree Classifier
        - 의사결정 트리(Decision Tree)의 머신러닝 알고리즘
        - Regression과 Classification 모두에 사용가능
- CrossValidation을 사용하여 모델 파라미터 선택
    - BinaryClassificationEvaluator를 Evaluator로 사용
    - ParamGridBuilder를 사용하여 ParamGrid를 생성
    - 뒤에 설명할 ML Pipeline을 인자로 지정
        - ML Pipeline를 만들 때 머신러닝 알고리즘을 마지막에 지정해야 함
<br>

## MinMaxScaler
- 기본적으로 VectorAssembler로 벡터 변환된(다수의 피쳐 컬럼들이 하나의 컬럼으로 벡터 형태로 들어간 것) 피쳐컬럼에 적용. 새로운 벡터 피쳐로 변환한다.
- 피쳐 값들이 0과 1사이로 스케일하도록 변환함.
- 스케일러를 적용하기 전보다 AUC의 점수가 소폭 상승할 수 있음.
<br>

## ML Pipeline 사용 절차
- 트레이닝셋에 수행해야하는 feature transformer들을 생성
- 사용하고자 하는 머신러닝 모델 알고리즘(Estimator)을 생성
- 이것들을 순서대로 파이썬 리스트에 추가
    - 머신러닝 알고리즘이 마지막으로 추가되어야 함
- 이 파이썬 리스트를 인자로 Pipeline 개체를 생성
- 이 Pipeline의 개체를 이용해 모델 빌딩: 2가지 방법 존재
    1. 이 Pipeline의 fit 함수를 호출하면서 트레이닝셋 데이터프레임을 지정해 바로 모델 생성
    2. 이 Pipeline을 ML Tuning 개체로 지정해서 여러 하이퍼 파라미터를 테스트해보고 가장 결과가 좋은 모델 선택(보통 cross-validation을 사용)
<br>

## ML Tuning 사용 절차
- 테스트하고 싶은 머신러닝 알고리즘 개체 생성(혹은 ML Pipeline)
- ParamGrid를 만들어 테스트하고 싶은 하이퍼 파라미터 지정
- CrossValidator 혹은 TrainValidationSplit 생성
    - CrossValidator에는 4가지의 인자가 필요하다. pipeline, paramGrid, evaluator, numFolds(폴드를 몇개로 나눌 것인지)
- fit 함수 호출해서 최선의 모델 선택
<br>
<br>

# 범용 머신러닝 모델 파일포맷: PMML - 머신러닝 모델이 만들어졌으면 다음 스텝은?
## 다양한 머신러닝 개발 플랫폼들이 존재한다.
- Scikit-Learn, PyTorch, Tensorflow, Spark MLlib등등...
- 이런 환경에서 통용되는 머신러닝 파일포맷이 있다면 어떨까?
- 그래서 나온 모듈 혹은 파일포맷등이 있음
    - PMML과 MLeap이 대표적
    - 이게 가능해지면 머신러닝 모델 서빙환경의 통일이 가능
        - 실상은 이런 공통 파일포맷이 지원해주는 기능이 미약해서 복잡한 모델의 경우에는 지원불가
<br>

# PMML
- Predictive Model Markup Language
- Machine Learning 모델을 마크업 언어로 표현해주는 XML 언어
    - 간단한 입력 데이터 전처리와 후처리도 지원. 하지만 아직도 제약사항이 많음
    - Java 기반
        - <https://github.com/jpmml/jpmml-evaluator>
        - 많은 회사들이 모델 실행을 위해서 자바로 PMML 엔진을 구현
    - PySpark에서는 pyspark2pmml를 사용
        - 하지만 내부적으로는 jpmml-sparkml이라는 자바 jar 파일을 사용
        - 너무 복잡함. 버전 의존도도 복잡
<br>

## PySpark에서 머신러닝 모델을 만든 후의 전체적인 절차 
1. ML Pipeline을 PMML 파일로 저장
    - 이를 위해 pyspark2pmml 파이썬 모듈 설치
        - jpmml-sparkml-executable-1.6.3.jar 파일 설치(Spark 3.0과 호환되는 버전임)
    - pyspark2pmml.PMMLBuilder를 이용해 ML Pipeline을 PMML 파일로 저장
2. PMML 파일을 기반으로 모델 예측 API로 론치
    - 다음 셋 중 하나를 사용할 수 있다.
    - Openscoring 프레임웍
    - AWS SageMaker
    - Flask + PyPMML
3. 이 API로 승객정보를 보내고 예측 결과를 받는 클라이언트 코드 작성
    - pmml 파일을 로딩한 뒤 파이썬 딕셔너리 형태로 피쳐값들을 입력해주면 예측값이 리턴된다.
<br>
<br>

# 총정리
## Spark은 차세대 분산 데이터 처리 프레임웍
    - 메모리에 올리는 데이터 포멧: RDD, 데이터프레임, 데이터셋
    - SparkSQL vs. 데이터프레임
    - Spark MLlib: Feature Transformer, ML Pipeline, MLTuning
<br>

## Spark은 정말 데이터가 클 때 필요한 기술
- 당장 모델링은 Scikit-Learn, Pytorch, Tensorflow(Keras)등으로도 충분
- 데이터 전처리도 판다스로 대부분 충분
    - Spark의 데이터프레임 vs. SparkSQL vs. 판다스의 데이터 프레임
- Spark을 잘 기억했다가 나중에 필요할 때 실제로 쓰기만 하면 됨!
<br>

## 데이터 팀의 발전
1. 서비스에서 직접 생기는 데이터와 써드파티를 통해 생기는 데이터가 데이터 인프라의 데이터 웨어하우스에 들어감.
2. 데이터 분석(지표 정의, 시각화, ...)
    - 데이터 인프라에 저장된 데이터를 기반(훈련용 데이터)으로 지도기계학습(supervised machine learning)을 통해 머신러닝 모델들을 개발하여 추천, 검색등을 개인화하는 것이 일반적인 패턴
    - 이때 데이터의 크기에 따라 대용량 분산처리 시스템이 필요
3. 데이터 과학 적용
    - 사용자 경험 개선(추천, 검색 등의 개인화)
<br>

## 데이터 과학자의 역할
- 머신러닝의 형태로 사용자들의 경험을 개선
    - 문제에 맞춰 가설을 세우고 데이터를 수집한 후에 예측 모델을 만들고 이를 테스트
        - 장시간이 필요하지만 이를 짧은 사이클로 단순하게 시작해서 고도화하는 것이 좋음
    - 데이터 과학자에게 필요한 스킬셋
        - 머신러닝/인공지능에 대한 깊은 지식과 경험
        - 코딩 능력(파이썬과 SQL. 특히 SQL!)
        - 통계 지식, 수학 지식
        - 끈기와 열정. 박사학위가 도움이 되는 이유 중 하나
<br>

## 훌륭한 데이터 과학자란?
- 열정과 끈기
- 다양한 경험
- 코딩 능력
- 현실적인 접근 방법
    - 애자일 기반의 모델링
    - 딥러닝은 모든 문제의 해답은 아님을 명심. 딥러닝은 블랙박스고 디버깅이 불가능.
- 과학적인 접근 방법
    - 지표기반(metrics) 접근
    - 내가 만드는 모델의 목표는 무엇이고 어떻게 측정할 것인가?
- 제일 중요한건 모델링을 위한 데이터의 존재 여부
<br>

## 명심할 것!
- 항상 배움에 집중하자
    - 정체기를 잘 버티고 즐겨서 넘기자!
        - 무엇이든 처음에는 완주하는 것이 더 중요!
        - 모르는 것을 남에게 정리해서 물어볼 수 있으면 어느정도 알게 된 것이다!
    - 매주 한번씩 글 써보기
        - 지난 일주일을 돌아보며 무엇을 배웠고 무엇이 혼란스러운지 글로 써보자
- 자신감을 갖자
    - 작은 목표를 매일 매주 세우고 그걸 완료해 나가면서 자신감을 키우자
    - 그 목표를 조금씩 키워보자
- 인생도 애자일하게!
    - 어디서건 시작해서 계속 배우면서 더 나은 곳으로 이동
    - Growth mindset이 중요
- 가능하면 인턴 꼭 해볼 것
    - 실제 업무를 하면서 배우는 것이 최고