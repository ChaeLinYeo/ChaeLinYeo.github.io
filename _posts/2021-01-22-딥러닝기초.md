---
title : "[Deep Learning: 신경망의 기초]딥러닝 기초"
data : 2021-01-22 00:15:28 -0400
categories : 프로그래머스인공지능스쿨
use_math: true
---
# 심층학습 최적화
훈련집합으로 학습을 마친 후, 현장에서 발생하는 새로운 샘플을 잘 예측해야함. ->즉, **일반화**능력이 좋아야함
- 훈련집합은 전체 데이터(실제, 알 수 없음) 대리자 역할
- 검증집합은 테스트집합 대리자 역할
- MSE, log-likelihood 등의 손실함수는 주어진 과업의 학습 성능(=판단 기준) 대리자 역할
<br>
<br>

## 목적함수: 교차 엔트로피와 로그우도
- **평균제곱 오차**를 다시 생각하기
- **교차 엔트로피** 목적함수
- **소프트맥스**함수와 **로그우도** 목적함수
<br>
<br>

## 평균제곱 오차 다시 생각하기
- **평균제곱 오차(MSE)** 목적함수
    - $e = {1 \above 1pt 2} \left \| y - o \right \|_{2}^{2}$
    - L2 norm으로 실제값-예측값 정량화함!
    - 오차가 클수록 $e$값이 크므로 벌점(정량적 성능)으로 활용됨
    - 벌점이 크면 현재 학습이 많이 개선되어야 함!
- 하지만, 큰 **허점**이 존재
    - $e_1 = 0.2815$, $e_2 = 0.4971$일 때
    - $e_2 = 0.4971$이 더 크기 때문에, 더 큰 벌점을 받아야 마땅함.
    - 신경망 학습 과정에서 학습은 오류를 줄이는 방향으로 가중치와 편향을 교정 <- 큰 교정이 필요함에도 작은 경사도로 작게 갱신됨
    - 경사도를 계산해봤을때 $e_1$가 나온 쪽의 출력값 이전의 경사도가 $e_2$가 나온 쪽의 출력값 이전의 경사도보다 더 크면 -> 더 많은 오류를 범한 상황이 더 낮은 벌점을 받은 꼴 -> 학습이 더딘 부정적 효과
- **이유**
    - 로지스틱 시그모이드를 사용하는 경우, 로지스틱 시그모이드 함수의 도함수 그래프를 보면 $wx+b$(활성함수 그래프의 가로축)가 커지면 경사도가 작아짐. 값이 클수록 더 작은 그래디언트 값을 얻음.
    - 따라서 큰 벌점을 부과하더라도 이에 대한 갱신이 더딤.
<br>

위의 문제를 해결하기 위해서는 첫번째, 활성함수를 ReLU로 바꾼다. 두번째, MSE를 다른 목적함수로 바꾼다. 바로 교차 엔트로피로!
<br>

## 교차 엔트로피 목적함수
- **교차 엔트로피**(cross entropy)
    - 정담(label)에 해당하는 y가 확률변수(2진분류로 0 or 1이라고 가정하자)
    - 확률 분포 : $P$는 정답, $Q$ 신경망(예측) 출력
    - 확률분포를 통일된 수식으로 쓰면,
        - $P(0)=1-y, Q(0)=1-o$
        - $P(1)=y, Q(1)=o$
    - **교차 엔트로피** $H(P,Q)=-\Sigma_x P(x)log_2Q(x) = -\Sigma_{i=1,...,k}P(e_i)log_2Q(e_i)$ 적용
        - $H(P, Q) = -\Sigma_{y\in {0,1}}P(y)log_2Q(y)$
<br>

- **교차 엔트로피 목적함수**
    - $e = -(ylog_2o + (1-y)log_2(1-o))$ 이 때, $o = \sigma(z)$이고 $z = wx + b$
    - 역할을 잘 수행하는지 확인
        - y가 1, o가 0.98일 때(예측이 잘된 경우)
            - 오류 $e = -(1 log_2 0.98 + (1-1)log_2(1-0.98))=0.0291$ 로서 낮은 값
        - y가 1, o가 0.00001일 때(예측이 잘못된 경우, 혹은 오분류된 경우)
            - 오류 $e = -(1 log_2 0.00001 + (1-1)log_2(1-0.00001))=13.2877$로서 높은 값
<br>

- 위 식을 c개의 출력 노드를 가진 경우로 확장
    - 출력 벡터 $o = (o_1, o_2, ..., o_c)^T$인 상황으로 확장
        - $e = 0\sum_{i=1,c}(y_ilog_2o_i + (1-y_i)log_2(1-o_i))$
<br>
<br>

## 소프트맥스 활성함수와 로그우도 목적함수
- **소프트맥스 함수**
    - $o_j = {e^{sj} \above 1pt \Sigma_{i=1,c}e^{si}}$
    - 동작 예
        - 소프트맥스는 최대를 모방 <- 출력 노드인 중간 계산 결과 $s_iL$의 최댓값을 더욱 활성화하고 다른 작은 값들은 억제
        - 모두 더하면 1이 되어 확률 모방
<br>

- **음의 로그우도** 목적함수
    - $e = -log_2o_y$
    - 모든 출력 노드값을 사용하는 MSE나 교차 엔트로피와 달리 $o_y$라는 **하나의 노드만 적용**
    - $o_y$는 샘플의 정답에 해당하는 노드의 출력값
- **소프트맥스와 로그우도**
    - **소프트맥스는 최댓값이 아닌 값을 억제하여 0에 가깝게 만든다**는 의도 내포
    - 신경망에 의한 샘플의 정답에 **해당하는 노드만 보겠다는 로그우도**와 잘 어울림
    - 따라서 **둘을 결합하여 사용하는 경우가 많음**
- 소프트맥스와 교차 엔트로피 목적함수
    - 로그우도 손실함수 ~ 교차엔트로피 최소화
<br>

- 소프트맥스 분류기
    - 다항 로지스틱 회귀분석의 예
    - 분류기의 최종 값을 확률로 표현
    - 소프트맥스와 로그우도 목적함수
<br>
<br>

## 컨볼루션(합성곱) 신경망(CNN, Convolution Neural Network)
- CNN은 **영상 인식**에서 많이 쓰임(image classification). 오늘날 영상 분야에서 다양하게 활용됨(분류, 검색, 검출, 분할 분야)
- 컴퓨터 비전의 어려운 점
    - 관점의 변화 : 동일한 객체라도 영상을 찍는 카메라의 이동에 따라 모든 픽셀값이 변화됨
    - 경계색(보호색)으로 배경과 구분이 어려운 경우
    - 조명에 따른 변화
    - 기형적인 형태의 영상 존재
    - 일부가 가려진 영상 존재
    - 같은 종류 간의 변화가 큼
전체적인, 통합적인 특징을 고려하여 학습해 특징을 추출해야 한다!  
<br>

- 컨볼루션 신경망
    - **컨볼루션층**(CONV) : 선형함수인 컨ㅂ로루션과 비선형 함수인 활성함수의 조합
    - **풀링층**(POOL) : 컨볼루션의 얻어진 특징을 통계적으로 압축
    - **전체 구조** : CONV-POOL-...-FC
<br>

- DMLP(다층퍼셉트론)와 CNN의 비교
    - DMLP
        - fully connection 구조로 높은 복잡도
        - 학습이 매우 느리고 과잉적합 우려
    - **CNN**
        - **컨볼루션 연산**을 이용한 **부분연결(희소연결)** 구조로 **복잡도 크게 낮춤**
            - 부분연결이란, 특정 필터가 한 픽셀씩 이동하는 것이다(로버트 필터 등~). 따라서 완전연결에 비해 복잡성이 크게 줄어든다! 사람의 시각적인 처리 프로세스와 유사함(부분 -> 전체이해)
        - **컨볼루션 연산**은 좋은 **특징 추출**
- CNN 특징
    - **격자(grid) 구조**(영상, 음성 등)를 갖는 데이터에 적합
    - **reception field**는 인간시각과 유사
    - 가변 크기의 입력 처리 가능
<br>

- CNN의 완전 연결 신경망(Fully connected neural networks)과 차별점
    - 학습에 의해 결정된 **복수의 커널들(혹은 필터들)**에 **대응되는 특징들을 추출**하는 층:CONV
        - 각 층의 입출력의 특징형상 유지(특징맵)
        - 영상의 **공간 정보**를 유지하면서 공간적으로 **인접한 정보의 특징을 효과적으로 인식**
        - 각 커널(필터)은 **파라미터를 공유**함으로써 완전 연결 신경망 대비 **학습 파라미터가 매우 적음**(즉 한번 사용한 파라미터를 계속 사용함. 학습 파라미터가 부분연결을 통해서 적어졌는데, 필터가 한 픽셀씩 이동하면서 파라미터가 동일하게 적용됨!)
    - 추출된 영상의 **특징을 요약하고 강화**하는 층(다층퍼셉트론에서는 없었으나 CNN과 같이 영상 처리할때 필요함. ) : POOL
    - **가변 크기**의 데이터 다루기
        - 완전연결신경망은 특징 벡터의 크기가 달라지면 연산 불가능
        - CNN은 가변 크기를 다룰 수 있는 강점
            - 컨볼루션층에서 보폭을 조정 / 풀링층에서 커널이나 보폭 조정하여 특징 맵 크기를 조절 
<br>

- 컨볼루션 신경망 예제 : <https://transcranial.github.io/keras-js/#/>
<br>
<br>

## 컨볼루션층
- **컨볼루션(합성곱) 연산**
    - 컨볼루션은 해당하는 요소끼리 곱하고 결과를 모두 더하는 **선형 연산**
    - $s(i) = z \circledast u = \sum_{x=-(h-1)/2}^{(h-1)/2} z(i+x)u(x)$ : 1차원 입력
    - $s(i) = z \circledast u = \sum_{x=-(h-1)/2}^{(h-1)/2} z(i+y, i+x)u(y,x)$ : 2차원 입력
        - 1차원 입력, 2차원 입력 식에서 u는 **커널(필터)**, z는 **입력**, s는 **출력(특징맵, feature map)**
        - 영상에서 **특징을 추출하기 위한 용도**로 사용됨(= **공간 필터**)
        ![png](/assets/images/2021-01-25/1.png)  
        - 위 이미지는 2차원 컨볼루션의 예이다. 위 이미지에서 output matrix가 바로 특징맵(피쳐맵)
        - 3차원 컨볼루션 연산의 경우 RGB를 예로 들 수 있다.
<br>

- **영상**에서의 **컨볼루션** 연산 예
    - Horizontal 필터를 사용해서 윤곽선에서 수평 선분들이 두드러지게 영상 처리
    - Vertical 필터를 사용해서 윤곽선에서 수직 선분들이 두드러지게 영상 처리
    - 필터를 통해 영상을 블러하게 만들수도 있고, 뚜렷하게 만들 수도 있다.
    - 이런 필터들을 CNN에서는 학습을 통해 결정한다!
- **영상**에서의 **ReLU(활성함수)** 연산의 예
    - 부분연결을 통해 컨볼루션 연산으로 뽑힌 특징들이 그 요소가 해당하는 위치에 얼마나 있는지를 결정한 후, 이 선형적 요소들을 비선형적 요소를 통해 얼마나 하이라이트해줄지 ReLU를 통해 결정한다.
    - feture map으로 나온 것들을 ReLU를 통해 특정 요소들을 더 부각시킨다.
<br>

- **덧대기**(padding)
    - 가장자리에서 영상의 크기가 줄어드는 효과 방지(각 층의 입출력의 특징**형상 유지**)
    - 크기를 맞춰주기 위해 테두리에 의미 없는 값들을 넣는다. 대부분 제로패딩을 쓴다.
- 편향(bias) 추가
    - 부분연결이긴 하지만 커널에 bias term을 추가해서 연산한다. 이 편향은 학습에 의해 생성.
<br>

- **가중치 공유(weight sharing)** 혹은 **묶인 가중치(parameter sharing)**
    - 모든 노드가 **동일한 커널**을 사용(즉 가중치를 공유)하므로 매개변수는 3개에 불과
    - **모델의 복잡도가 크게 낮아짐**
<br>

- **다중 특징 맵 추출**
    - **커널의 값에 따라 커널이 추출하는 특징이 달라짐**
    - 따라서 하나의 커널만 사용하면 너무 빈약한 특징이 추출됨
    - 실제로는 수십~수백 개의 커널을 사용
<br>

- **특징 학습**
    - **커널**을 사람이 설계하지 않고, **학습으로 찾음**
        - $u_i^k$는 $k$번째 커널의 $i$번째 매개변수
    - 예) 2차원 영상이 $7 * 7$ 커널을 64개 사용한다면, 학습은 $(7 * 7 + 1) * 64 = 3200$개의 매개변수를 찾아내야 함(+1은 bias임!)
    - DMLP와 마찬가지로 **오류 역전파**로 **커널을 학습**
<br>

- 컨볼루션 연산에 따른 CNN의 특성
    - 이동에 동변(신호가 이동하면 이동 정보가 그대로 특징 맵에 반영) -> 영상 인식에서 물체 이동이나 음성 인식에서 발음 지연에 효과적으로 대처
- 병렬분산 구조
    - 각 노드는 독립적으로 계산 가능하므로 병렬 구조
    - 노드는 깊은 층을 거치면서 전체에 영향을 미치므로 분산 구조 
<br>

- 큰 **보폭(stride)**에 의한 다운샘플링
    - 지금까지는 모든 화소(픽셀)에 커널 적용 -> 보폭을 1로 설정한 셈(한칸씩 필터가 움직임)
    - 일반적으로 보폭이 $k$면, $k$개 마다 하나씩 샘플링하여 커널 적용 -> 2차원 영상의 경우 특징 맵이 $1/k^2$로 작아짐
<br>

- **텐서** 적용
    - 3차원 이상의 구조에도 적용 가능
        - 예: RGB 컬러 영상은 $3 * m * n$의 3차원 텐서
<br>

- **3차원** 구조의 데이터 적용
    - **채널**이 $k$개인 **3차원** 격자 구조
    - **4차원** 텐서로 표현하는 데이터
        - 예 : 컬러 동영상$(3 * s * m * n)$, MRI 뇌영상$(1 * s * m * n)$
        - $k * h * h * h$커널을 $s * m * n$공간을 이동하면서 적용
<br>
<br>

## 풀링층
- **풀링(pooling)** 연산
    - 컨볼루션 연산을 하고 나온 출력물, 즉 피쳐맵에 적용하여 사이즈를 다운스케일한다. 보통 원래 피쳐맵의 크기를 절반씩 줄ㅇ니다.
    - **최대 풀링, 평균 풀링**, 가중치 평균 풀링 등
        - 최대풀링(맥스 풀링), 평균풀링을 많이 쓰며, 맥스풀링은 요소 중 가장 큰 값을 취하고 평균풀링은 평균값을 취한다.
    - 보폭을 크게 하면 다운샘플링 효과 
<br>

- 풀링 연산의 특성(풀링을 왜 쓰는가?)
    - 풀링은 상세 내용에서 **요약** 혹은 평균 등의 통계적 **대표성**을 추출함
    - 매개변수가 없음
    - 특징 맵의 수를 그대로 유지함(크기 X)
    - 연산 효율화(연산 횟수, 연결 가중치 개수 줄임)
    - 작은 변화에 둔감 -> 물체 인식이나 영상 검색 등에 효과적임
<br>
<br>

## 전체 구조
- 빌딩 블록
    - CNN은 빌딩 믈록을 이어 붙여 **깊은 구조로 확장**
    - 전형적인 빌딩블록 : **컨볼루션층 -> 활성함수(주로 ReLU 사용) -> 풀링층**
    - 다중 커널을 사용하여 다중 특징 맵을 추출함
    ![png](/assets/images/2021-01-25/2.png)  
<br>

- 컨볼루션 층의 출력 **크기**와 **매개변수 수**
    - 입력 : W1 * H1 * D1
    - K개 F * F 커널, 보폭 S, 덧대기 P
        - 출력의 크기 :
            - W2 * H2 * D2
            - W2 = (W1-F+2P)/S+1
            - H2 = (H1-F+2P)/S+1
            - D2 = K
        - 매개변수의 수 : 
            - 커널마다 (F * F * D1)개의 가중치와 1개의 바이어스를 가짐. 따라서, 전체 매개변수의 수는 F * F * D1)K + K
    - 일반적으로 F = 2, S = 2 혹은 F = 3, S = 1을 사용함
- 예제
    - 입력 크기 : 32 * 32 * 3
    - 10개의 5 * 5 커널, 보폭 1, 덧대기 2
    - 출력 크기 : (32 + 2 * 2 - 5)/1 + 1 = 32 -> 32 * 32 * 10
    - 층의 매개변수 개수 : 5 * 5 * 3 + 1 = 76(+1 편향 추가) -> 76 * 10 = 760
<br>

- 초창기 CNN 사례로서 **LeNet**-5
    - **특징 추출** : **CONV-POOL-CONV-POOL-CONV**의 다섯 츠응ㄹ 통해 **28*28 명암 영상**을 **120차원의 특징 벡터**로 **변환**
        - 평균 풀링 사용
    - **분류** : 은닉층이 하나인 MLP
    - CNN의 첫 번째 성공사례: 필기 숫자 인식기 만들어 수표 인식 자동화 시스템 구현 
<br>

- CNN CIFAR10 훈련 예제 : <http://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html>
- CNN 시각화 예제 : <https://poloclub.github.io/cnn-explainer/>
<br>
<br>

# 컨볼루션 신경망 사례연구
## AlexNet
- 구조
    - **컨볼루션층 5개**와 **완전연결(fully connected, FC) 층 3개**
    - 컨볼루션층은 200만개, FC층은 6500만개 가량의 매개변수
        - FC층에 30배 많은 매개변수 -> **향후 CNN은 FC층의 매개변수를 줄이는 방향으로 발전**
    - 1000개의 분류를 위해 소프트맥스 함수 사용
    - 당시 GPU의 메모리 크기 제한으로 인해 GPU#1, GPU#2으로 분할하여 학습 수행
        - 3번째 컨볼루션 층은 GPU#1과 GPU#2의 결과를 함께 사용(inter-GPU connections)
        - GPU#1 : 색과 관련되지 않은 특징 추출
        - GPU#2 : 색과 관련된 특징 추출
        - 요즘에는 GPU연산을 나누지 않더라도 하나의 GPU에서 처리 가능
    - 컨볼루션 층 보폭으로 다운샘플링
- AlexNet이 학습에 성공한 요인
    - 외적 요인
        - **ImageNet** 이라는 대규모 사진 데이터
        - **GPU**를 사용한 병렬처리
    - 내적 요인
        - 활성함수로 **ReLU** 사용
        - **지역 반응 정규화(local response normalization)** 기법 적용 -> 지금은 쓰이지 않음!
            - 인간 신경망 측면억제(lateral inhibition)모방, ReLU 활성화 규제
            - 1번째, 3번째 최대 풀링 전 적용
        - 과잉적합 방지하는 여러 규제 기법 적용
            - **데이터 확대**(잘라내기와 반전으로 2048배로 확대)
            - **드롭아웃**(완전연결층에서 사용) -> 특징들이 몰리게끔 해줌
    - 테스트 단계에서 앙상블 적용
        - 입력된 영상을 잘라내기와 반전을 통해 증가하고 증가된 영상들의 예측 평균으로 최종 인식
        - 2~3%만큼 오류율 감소 효과
<br>
<br>

## VGGNet
- VGGNet의 핵심 아이디어
    - 3*3의 **작은 커널**을 사용
    - **신경망을 더욱 깊게 만듦**(신경망의 깊이가 어떤 영향을 주는지 확인)
    - 컨볼루션층 8~16개를 두어 AlexNet의 5개에 비해 2~3배 깊어짐
- 16층짜리 VGG-16 (CONV 13층 + FC 3층)
- **작은 커널**의 이점
    - GoogleNet의 인셉션 모듈처럼 이후 깊은 신경망 구조에 영향
    - 큰 크기의 커널은 여러 개의 작은 크기 커널로 분해될 수 있음 -> 매개변수의 수는 줄어들면서 신경망은 깊어지는 효과
        - 예: 5 * 5 커널을 2층의 3 * 3 커널로 분해하여 구현
        - 예: 3 * 3 커널을 1 * 3 커널과 3 * 1 커널로 분해하여 구현. 유사하게 n * n 커널은 1 * n 커널과 n * 1 커널로 분해될 수 있으며, n이 클수록 매개변수의 수는 줄어드는 효과가 큼
- **1 * 1 커널**
    - 신경망 속의 신경망 연구에서 유래
    - VGGNet은 적용 실험을 하였지만 최종 선택하지는 않음(GoogleNet에서 사용됨)
    - 차원 통합
    - **차원 축소 효과**
        - c2 > c3: 차원 축소(연산량 감소)
<br>
<br>

## GoogleNet
- GoogleNet의 핵심은 **인셉션 모듈**
    - 수용장(입력을 패치 뜬 것 즉 전체 인풋에서 필터 적용할 일정 사이즈의 부분)의 **다양한 특징을 추출**하기 위해 NIN의 구조를 확장하여 **복수의 병렬적인 컨볼루션 층**을 가짐(한 층에서의 컨볼루션이 3 * 3, 7 * 7 등 다양한 크기의 수용장을 가질 수 있는 컨볼루션을 적용하면서 출력을 내뱉는다.)
    - NIN 구조
        - 기존 컨볼루션 연산을 MLPConv 연산으로 대체
            - 커널 대신 비선형 함수를 활성함수로 포함하는 MLP를 사용하여 특징 추출 유리함
        - 신경망의 미소 신경망(micro neural network)가 주어진 수용장의 특징을 추상화 시도
        - 전역 평균 풀링 사용(global average pooling)
        - 필터를 고정형으로 쓰는게 아니라 다양한 수용장을 가질 수 있도록 가변적인 수용장을 가지는 연산의 가능성을 확인한 것이다.
- GoogleNet은 NIN 개념을 확장한 신경망
    - 인셉션 모듈
        - 마이크로 네트워크로 MLPConv 대신 **네 종류의 컨볼루션 연산** 사용 -> **다양한 특징 추출**(다양한 수용장을 받을 수 있도록)
        - 1 * 1 컨볼루션을 사용하여 차원 축소(채널의 depth를 줄임, 연산량을 줄일 수 있음)
            - 매개변수 수(=특징 맵의 수)를 줄임 + 깊은 신경망
        - 3 * 3, 5 * 5 같은 다양한 크기의 컨볼루션을 통해서 다양한 특징들을 추출
- 인셉션 모듈을 9개 결합한 것이 GoogleNet
    - 매개변수가 있는 층 22개, 없는 층(풀링) 5개로 총 27개 층
    - 완전 연결층(FC)은 1개에 불과
        - 1백만 개의 매개변수를 가지며, VGGNet의 완전 연결층에 비하면 1%에 불과
    - **보조 분류기**(auxiliary classifier)
        - 원 분류기의 오류 역전파 결과와 보조 분류기의 오류 역전파 결과를 결합하여 **경사 소멸 문제 완화**
        - 학습할 때 도우미 역할(가중치 학습 도움)을 하고, 추론할 때 제거됨
- 학습이 다른 신경망들에 비해 덜 민감하게 잘 됨. 다른 신경망들은 많이 센시티브한 경향이 있음.
<br>
<br>

## ResNet
- **잔류(잔차)학습**(residual learning)이라는 개념을 이용하여 성능 저하를 피하면서 **층 수를 대폭 늘림**
- 잔류 학습은 지름길 연결된 $x$를 더한 $F(x)+x$에 $\tau$를 적용. $F(x)$는 잔류(잔차, residual). $y = \tau(F(x)+x)$
- 자기자신에서 비롯해서 신경망에 의해 미소한 변화가 있는 것을 자기 자신으로부터 얼마나 변화가 있는지로 이해한다. 자기자신에서부터 얼마나 변할지 학습을 시켜준다. 얕은 신경망을 조금씩 학습시키는 것과 비슷하다. 전체를 학습시키는 것이 아니라!
- 지름길 연결을 두는 이유는?
    - 깊은 신경망도 최적화가 가능해짐
        - 단순한 학습의 관점의 변화를 통한 신경망 구조 변화
            - 단순 구조의 변경으로 매개변수 수에 영향이 없음
            - 덧셈 연산만 증가하므로 전체 연산량 증가도 미비함
    - 깊어진 신경망으로 인해 정확도 개선 가능함
    - 경사 소멸 문제 해결
        - 경사도를 구하는 식에서 결과가 -1이 될 가능성이 거의 없음. 경사도가 0으로 완전히 사라질 일이 없음.
- VGGNet과 같은 점 : 3 * 3 커널 사용(작은 커널 사용)
- VGGNet과 다른 점
    - 잔류 학습 사용
    - 전역 평균 풀링 사용(FC층 제거)
    - 배치 정규화 적용(드롭아웃 적용 불필요)
<br>
<br>

## 생성 모델
- 생성 모델이란?
    - 생성모델은 주어진 라벨 Y가 있을 때 X를 생성하는 것이다. 데이터 자체에 대해 의미를 갖고 접근한다. 
    - P(x) 또는 P(x|y), P(x,y) 추정.
    - 비지도 학습
    - 분류 모델은 P(y|x) 추정, 지도 학습. 주어진 X가 있을 때 Y, 즉 라벨값을 예측하는 것이다.
- 실제 상황에서 생성 모델
    - 현실에 내재한 데이터 발생분포는 알아낼 수 없다.
    - 이 데이터 발생분포를 모방하는 모델의 확률분포를 명시적으로 추정하는 것도 어렵다.
    - 현대 기계 학습은 주로 딥러닝 모델을 사용하여 이 확률 분포를 암시적으로 표현.
<br>
<br>

## GAN(generative adversarial network)
- GAN의 핵심
    - 생성기(generator) G와 분별기(discriminator) D의 대립 구도
        - G는 가짜 샘플 생성(위조지폐범)
        - D는 가짜와 진짜를 구별(경찰)
    - GAN의 목표는 위조지폐범의 승리(G가 만들어내는 샘플을 D가 구별하지 못하는 수준까지 학습)
    - 신경망 두개가 적대적으로 서로 핑퐁게임 하듯이 학습한다!