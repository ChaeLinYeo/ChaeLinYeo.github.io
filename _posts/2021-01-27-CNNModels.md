---
title : "[Deep Learning: 신경망의 기초]CNN Models"
data : 2021-01-27 00:15:28 -0400
categories : 프로그래머스인공지능스쿨
use_math: true
---
# 심층학습 최적화
## 평균제곱 오차(MSE) 다시 생각하기
- **평균제곱 오차(MSE)** 목적함수
    - $e = {1 \above 1pt 2} \left \| y - o \right \|_{2}^{2}$
    - L2 norm으로 실제값-예측값 정량화함!
    - 오차가 클수록 $e$값이 크므로 벌점(정량적 성능)으로 활용됨
    - 벌점이 크면 현재 학습이 많이 개선되어야 함!
- 하지만, 큰 **허점**이 존재
    - $e_1 = 0.2815$, $e_2 = 0.4971$일 때
    - $e_2 = 0.4971$이 더 크기 때문에, 더 큰 벌점을 받아야 마땅함.
    - 신경망 학습 과정에서 학습은 오류를 줄이는 방향으로 가중치와 편향을 교정 <- 큰 교정이 필요함에도 작은 경사도로 작게 갱신됨
    - 경사도를 계산해봤을때 $e_1$가 나온 쪽의 출력값 이전의 경사도가 $e_2$가 나온 쪽의 출력값 이전의 경사도보다 더 크면 -> 더 많은 오류를 범한 상황이 더 낮은 벌점을 받은 꼴 -> 학습이 더딘 부정적 효과
- **이유**
    - 로지스틱 시그모이드를 사용하는 경우, 로지스틱 시그모이드 함수의 도함수 그래프를 보면 $wx+b$(활성함수 그래프의 가로축)가 커지면 경사도가 작아짐. 값이 클수록 더 작은 그래디언트 값을 얻음.
    - 따라서 큰 벌점을 부과하더라도 이에 대한 갱신이 더딤.
<br>

위의 문제를 해결하기 위해서는 첫번째, 활성함수를 ReLU로 바꾼다. 두번째, MSE를 다른 목적함수로 바꾼다. 바로 교차 엔트로피로!
<br>

## 교차 엔트로피 목적함수
- **교차 엔트로피**(cross entropy)
    - 정담(label)에 해당하는 y가 확률변수(2진분류로 0 or 1이라고 가정하자)
    - 확률 분포 : $P$는 정답, $Q$ 신경망(예측) 출력
    - 확률분포를 통일된 수식으로 쓰면,
        - $P(0)=1-y, Q(0)=1-o$
        - $P(1)=y, Q(1)=o$
    - 신경망 출력으로 표기하면,
        - $o = \sigma(z)$
        - $z = wx + b$
    - **교차 엔트로피** $H(P,Q)=-\Sigma_x P(x)log_2Q(x) = -\Sigma_{i=1,...,k}P(e_i)log_2Q(e_i)$ 적용
        - $H(P, Q) = -\Sigma_{y\in {0,1}}P(y)log_2Q(y)$
<br>

- 교차 엔트로피를 사용하면 잘못된 학습으로 오분류된 손실은(벌점, 오차)를 무한대에 가깝게 크게 주고, 잘된 학습으로 제대로 분류된 손실은 0으로 나온다.
<br>

- **교차 엔트로피 목적함수**
    - $e = -(ylog_2o + (1-y)log_2(1-o))$ 이 때, $o = \sigma(z)$이고 $z = wx + b$
    - 역할을 잘 수행하는지 확인
        - y가 1, o가 0.98일 때(예측이 잘된 경우)
            - 오류 $e = -(1 log_2 0.98 + (1-1)log_2(1-0.98))=0.0291$ 로서 낮은 값
        - y가 1, o가 0.00001일 때(예측이 잘못된 경우, 혹은 오분류된 경우)
            - 오류 $e = -(1 log_2 0.00001 + (1-1)log_2(1-0.00001))=13.2877$로서 높은 값
<br>

- 위 식을 c개의 출력 노드를 가진 경우로 확장
    - 출력 벡터 $o = (o_1, o_2, ..., o_c)^T$인 상황으로 확장
        - $e = 0\sum_{i=1,c}(y_ilog_2o_i + (1-y_i)log_2(1-o_i))$
    - 예 : $y\in {개, 고양이, 사람}$인 경우 $P(y)=[0, 0, 1]$와 $Q(y) = [0.2, 0.3, 0.5]$일 때, 교차 엔트로피는 $-log(0.5)$이다.
<br>
<br>

## 소프트맥스 활성함수와 로그우도 목적함수
- 출력값이 확률분포를 갖고자 할 때 쓴다.
- **소프트맥스 함수**
    - $o_j = {e^{sj} \above 1pt \Sigma_{i=1,c}e^{si}}$
    - 동작 예
        - 소프트맥스는 최대를 모방 <- 출력 노드인 중간 계산 결과 $s_iL$의 최댓값을 더욱 활성화하고 다른 작은 값들은 억제
        - 모두 더하면 1이 되어 확률 모방
        - 결과 중 가장 큰 값을 라벨값으로 선택함.
- 출력층의 변화에 따라 소프트맥스의 결과도 최대 출력에 더 가까워짐. 따라서 부드러운 최대 함수로 불림. max함수의 경우 출력값을 예를 들어 0, 0, 1로 만들어서 1을 선택하게 한다면, 소프트맥스는 0.1131, 0.0508, 0.8360으로 만들어서 이중 가장 큰 값임 0.8360을 선택하게 하고, 이 세 값을 더하면 1이 된다.
<br>

- **음의 로그우도** 목적함수
    - $e = -log_2o_y$
    - 모든 출력 노드값을 사용하는 MSE나 교차 엔트로피와 달리 $o_y$라는 **하나의 노드만 적용**
    - $o_y$는 샘플의 정답에 해당하는 노드의 출력값
- **소프트맥스와 로그우도**
    - **소프트맥스는 최댓값이 아닌 값을 억제하여 0에 가깝게 만든다**는 의도 내포
    - 신경망에 의한 샘플의 정답에 **해당하는 노드만 보겠다는 로그우도**와 잘 어울림
    - 따라서 **둘을 결합하여 사용하는 경우가 많음**
- 소프트맥스와 교차 엔트로피 목적함수
    - 로그우도 손실함수 ~ 교차엔트로피 최소화
<br>

- 소프트맥스 분류기
    - 다항 로지스틱 회귀분석의 예
    - 분류기의 최종 값을 확률로 표현
    - 소프트맥스와 로그우도 목적함수
<br>
<br>

# 성능 향상을 위한 요령
- 데이터 전처리
- 가중치 초기화
- 탄력(가속도, 관성)
- 적응적 학습률
- 활성함수
- 배치 정규화
<br>

## 데이터 전처리
- 규모(scale) 문제
    - 예)건강에 관련된 데이터 (키(m), 몸무게(kg), 혈압)^T
        - 1.885m와 1.525m는 33cm나 차이가 나지만 특징 값 차이는 불과 0.33
        - 65.5kg과 45.0kg은 20.5라는 차이
        - 첫 번째(키, m)와 두 번째(몸무게, kg) 특징은 양수이며, 대략 100배 규모 차이!
            - $1.885 * w_1$와 $65.5 * w_2$는 규모 차이가 100배가 있기 때문에 의존성이 많이 생긴다.
            - 몸무게에 연결된 가중치의 갱신이 키에 연결된 가중치보다 훨씬 크게 변한다. 따라서 불균형하게 학습된다.
        - 첫 번째 특징(키)에 연결된 가중치는 두 번째 특징(몸무게)에 연결된 가중치에 비해 100여 배 느리게 학습됨(불균형하게 학습되기 때문) -> 느린 학습의 요인
        - 따라서 데이터의 규모(scale, 단위)을 비슷하게 맞춰야함.
- 모든 특징이 양수인 경우의 문제
    - 위의 예제에서 키, 몸무게, 혈압이 모두 양수일 경우, output gradient에 의해 연결되는 모든 가중치들의 증감이 계속 왔다갔다 하게 된다.(그래디언트가 +이면 -> -가 되었다가 -> 다시 +가 되었다가 -> 다시 -가 되었다가...)
    - 가중치가 뭉치로 증가 또는 감소하면 최저점을 찾아가는 경로가 갈팡질팡하여 느린 수렴
<br>

- **"정규화(normalization)**는 규모 문제와 양수 문제를 해결해줌
    - 특징별 독립적으로 적용. 축을 바꿔 평균을 바꾸고 퍼짐의 정도 즉 표준편차를 바꿈
    - 평균이 0이 되도록 변환, 표준편차가 1이 되도록 변환(정규분포 z transform)
    - 통계학의 정규 분포를 활용한 표준화 변환을 적용한 경우
        - $x_i^{new} = {x_i^{old} - \mu_i \above 1pt \sigma_i}$
    - 최대 최소 변환을 적용한 경우
        - $x_i^{new} = {x_i^{old} - min(x_i) \above 1pt max(x_i) - min(x_i)}$
<br>

- **명목 변수(normal value)**을 **원핫(one-hot)** 코드로 변환
    - 명목 변수: 객체간 서로 구분하기 위한 변수
        - 예) 성별: 남(1), 여(2), 체질: 태양인(1), 태음인(2), 소양인(3), 소음인(4)
    - 명목 변수는 거리 개념이 없음
    - 원핫 코드는 값의 개수만큼 bit를 부여
        - 예) 성별은 2비트 부여, 체질은 4비트 부여
        - 예) 키 1.755m, 몸무게 65.5kg, 혈압 122, 남자, 소양인 샘플: (1.755, 65.5, 122, 1, 3) -> (1.755, 65.5, 122, [1, 0], [0, 0, 1, 0])
<br>

- **대칭적 가중치** 문제
    - 층과 층 사이에 모든 값들이 대칭적으로 연결되어 있거나, 동일한 값으로 세팅되어 있는 극단적인 경우 중간 representation값들이 서로 동일한 값이 되어버림. 모든 노드가 똑같은 갱신을 중복해서 하게 됨.
    - 두 노드가 같은 일을 하는 중복 발생
    - 난수로 초기화함으로써 대칭 파괴. 대칭성을 없애서 층과 층 사이의 값들을 서로 다른 값으로 만듦.
    - **난수**로 가중치 초기화
        - 가우시안 또는 균일(uniform) 분포에서 난수 추출. 두 분포는 성능 차이는 거의 없음
        - 난수 범위는 무척 중요함
        - 다음 두 식 중 하나로 r을 결정한 후 [-r, r] 사이에서 난수 발생
            - $r = {1 \above 1pt \sqrt{n_{in}}}$
            - $r = {\sqrt 6 \above 1pt \sqrt{n_{in}} + \sqrt{n_{out}}}$
            - 노드로 들어오는 에지 개수 $n_{in}$과 노드에서 나가는 에지 개수 $n_out$
        - 편향은 보통 0으로 초기화
<br>
<br>

## 가중치 초기화
- 초기화가 너무 작으면, 모든 활성 값이 0이 됨. ack propagation시 경사도도 0이되어 학습이 안됨
- 초기화가 너무 크면, 활성화함수의 값이 포화되어 back propagation시 경사도가 0이되어 학습이 안됨
- 초기화가 적당하면, 모든 층에서 활성 값의 분포가 좋음. 적절한 학습이 수행됨.
<br>
<br>

## 탄력(가속소, 관성) momentum
- **경사도의 잡음** 현상
    - 기계 학습은 훈련집합을 이용하여 매개변수의 경사도를 추정하므로 잡음 가능성 높음
    - **탄력(가속도, 관성)momentum**은 경사도에 부드러움을 가하여 잡음 효과 줄임
        - 관성(가속도): 과거에 이동했던 방식을 기억하면서 기존 방향으로 일정 이상 추가 이동함 -> 수렴 속도 향상(local minima, saddle point에 빠지는 문제 해소)
- **관성을 적용한 가중치 갱신 수식**
    - $v = \alpha v + \rho {\partial J \above 1pt \partial \Theta}$
    - $\Theta = \Theta - v$
    - 속도 벡터 $v$는 이전 경사도를 누적한 것에 해당함(처음 $v=0$로 출발)
    - $\alpha$의 효과(관성의 정도)
        - $\alpha = 0$이면 관성이 적용 안 된 이전 경사도 갱신 공식과 동일
        - $\alpha$가 1에 가까울수록 이전 경사도 정보에 큰 가중치를 주는 셈 -> $\Theta$가 그리는 궤적이 매끄러움
        - 보통 0.5, 0.9, 0.99사용(또는 0.5로 시작하여 epoch가 지남에 따라 점점 키워 0.99에 도달하는 방법)
- **관성의 효과**
    - 지나침(overshooting)현상 누그러뜨림. 지그재그를 완화시킴!
- **네스테로프 가속 경사도** 관성
    - 현재 $v$ 값으로 다음 이동할 곳 $\widetilde{\Theta}$를 예견한 후, 예견한 곳의 경사도를 사용(멈춤 용이)
    - 관성을 적용한 가중치 갱신은 그래디언트를 구하고 과거의 경사도를 누적한걸 바탕으로 세타값을 갱신
    - 네스테로프 가속 경사도 관성은 현재 v값을 구할때 다음 값으로 이동시켜놓고(세타값 예견) 이동시켜놓은것에서부터 경사도를 구한다. 이동시켜놓고 그래디언트를 구하기 때문에 수렴이 더 잘되고 멈춤도 더 쉽다.
    - 둘의 차이점 기억! 구현의 차이점이 있다.
<br>
<br>

## 적응적 학습률
- **학습률** $\rho$의 중요성
    - 너무 크면 지나침(overshooting)에 따른 진자현상(지나치게 큰 지그재그), 너무 작으면 수렴이 느림
- **적응적 학습률(adaptive leargning rates)** 혹은 pre-parameter learning rates(파라미터마다 학습률)
    - 경사도에 학습률을 곱하면, 기존 경사도 갱신은 모든 매개변수에 같은 크기의 학습률을 사용하는 셈
    - **적응적 학습률**은 **매개변수마다** 자신의 상황에 따라 **학습률을 조절**해 사용
        - 예) 학습률 담금질(SA) : 이전 경사도와 현재 경사도의 부호가 같은 매개변수는 값을 키우고 다른 매개변수는 값을 줄이는 전략
<br>

- **AdaGrad**(adaptive gradient)
    - 이전 경사도를 누적한 벡터r이 크면 갱신값을 작게 해서 조금만 이동
    - 이전 경사도를 누적한 벡터r이 작으면 갱신값을 크게 해서 많이 이동
    - 상황에 따라 보폭을 정해주는 **적응적 학습률**
<br>

- **RMSProp**
    - AdaGrad의 단점 : 오래된 경사도와 최근 경사도는 **같은 비중**의 역할을 가짐 -> 이전 경사도를 누적한 벡터r이 점점 커져 수렴 방해할 가능성
    - RMSProp은 **가중 이동 평균** 기법 적용
        - $r = \alpha r + (1 - \alpha)g\odot g$
        - $\alpha$가 작을수록 최근 것에 비중을 둠
        - 보통 $\alpha$로 0.9, 0.99, 0.999를 사용
<br>

- **Adam**(adaptive gradient)
    - RMSProp + Momentum인 방법
    - RMSProp에 **관성을 추가**로 적용한 알고리즘
    - Adam을 신경망에서 옵티마이저로 많이 씀.