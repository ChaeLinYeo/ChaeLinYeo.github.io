---
title : "[TIL]선형분류1"
data : 2021-01-14 00:15:28 -0400
categories : 프로그래머스인공지능스쿨
use_math: true
---
분류문제는 머신러닝에서 가장 중요한 부분이다.  
- 분류의 목표 : 입력벡터를 하나의 클래스로 할당하는 것
- 분류를 위한 결정이론
    - 확률적 모델 
        - 생성모델 : 클래스 C_k가 주어져 있을 때 인풋 x의 확률을 모델링하고 클래스의 확률을 모델링하게 된다. 이 두가지 확률이 주어지게 되면, 베이즈 정리를 사용해 사후확률을 구할 수 있다.
        - 식별모델 : x에 대한 density를 구할 필요 없이, 직접적으로 바로 클래스의 사후확률을 모델링하게 된다. 그 결과에 따라 적절하게 최종적인 클래스를 할당할 수 있다.
    - 판별함수 : 확률을 계산하지 않고 입력 x를 클래스로 바로 할당하는 함수를 찾는 것이다.
<br>
<br>

## 판별함수
- 분류를 위한 최소제곱법 
    - 선형회귀때는 목표값이 실수값으로 주어져있었다. 지금은 실수값이긴 하지만 유한한 개수의 클래스만 주어져 있다. 
    - 결론부터 말하자면, 분류문제를 풀기 위해서 최소제곱법을 쓰는 것은 좋은 방법이 아니다!
- 퍼셉트론 알고리즘
    - 또다른 판별함수 방법인 퍼셉트론 알고리즘
    - 잘못 분류된 샘플 점에 대해 업데이트되는것이 반복됨
    - 한번 업데이트 되고 난 점의 에러는 이전단계의 에러값보다 작아진다. 업데이트 할 때마다 에러값이 그 점에 대해서는 줄어든다.
    - 최소제곱법보다는 퍼셉트론이 더 좋은 방법이다. 현대 쓰이는 뉴럴 네트워크의 기초가 되었다. 
최소제곱법, 퍼셉트론 : Output을 출력하지만 하나의 값을 출력할 뿐이지 그것의 확률을 계산해주진 않기 때문에 이런 점에서 한계가 있다. 
<br>
<br>

## 확률적 모델
- 데이터의 분포에 관해 가정을 두면 선형적인 결정경계가 그 결과로 유도됨
클래스가 주어졌을때 x의 확률, 그리고 클래스와 확률을 먼저 모델링한 뒤 베이즈 정리를 사용해 x가 주어졌을 때 클래스의 확률 즉 사후확률을 구한다.  
판별함수 방법에서는 에러함수를 설정하고 에러함수를 최소화시키기 위한 최적의 파라미터를 찾는게 목적이었다.  
확률적인 모델은 데이터의 분포를 모델링하면서 분류문제를 결과적으로 풀게 된다.  
- 확률적 생성 모델
    - 최대우도해 : 최대우도해를 사용해서 파라미터들의 최적의 값을 찾는다.
- 확률적 식별 모델
    - 로지스틱 회귀
        - 생성모델에서는 굉장히 많은 개수의 파라미터를 다 구해야 한다. M(차원)에 대해서 쿼드라틱한 개수이다. M이 커지게 되면 상당히 많은 수의 파라미터를 구해야 하는 부담이 생기는데, 로지스틱에서는 리니어한 개수의 파라미터만 구하면 된다.
    - 최대우도해 : 늘 하듯이 로그값 구해 마이너스를 붙여서 로그우도값을 최소화하는식으로 한다.
최소제곱법으로 잘 안됐던 이유가 목표값의 분포가 가우시안을 따르지 않았기 때문이다. 하지만 확률적 식별 모델에서는 가우시안 분포를 따르기 때문에 최대우도해를 사용했을 때 정당한 에러함수는 이러한 크로스 엔트로피 에러함수가 된다.  
분포문제를 위해서는 크로스 엔트로피 에러함수를 사용해야 한다! 반대로 회귀문제에서는 최소제곱법을 사용해야 한다.  
문제에 맞는 에러함수를 사용해야 한다.  